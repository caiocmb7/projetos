{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302f1b04-204d-442f-8a53-934e031a4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.base import BaseSampler\n",
    "from imblearn.over_sampling.base import BaseOverSampler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "\n",
    "import sdgym\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import (\n",
    "    CTGANSynthesizer,\n",
    "    TVAESynthesizer,\n",
    "    GaussianCopulaSynthesizer,\n",
    "    CopulaGANSynthesizer,\n",
    ")\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.evaluation.single_table import (\n",
    "    evaluate_quality,\n",
    "    get_column_plot,\n",
    "    get_column_pair_plot,\n",
    "    run_diagnostic,\n",
    ")\n",
    "from sdv.sampling import Condition\n",
    "from imblearn.utils import check_target_type\n",
    "from scipy import sparse\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\", font_scale=0.5)\n",
    "custom_palette = [\"#8b4513\", \"#90ee90\", \"#545454\", \"#6a287e\", \"#f0be00\"]\n",
    "sns.set_palette(custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8bbd1-ceaf-4339-9437-4b61aca306b7",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bbce24-efc4-495f-a655-7605696a000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(df, columns):\n",
    "    dummy_variables = []\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(df[column], prefix=column)\n",
    "        dummy_variables.append(dummies)\n",
    "    return dummy_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3084bd82-c3b2-4198-87aa-ee4621466dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_transform(df, columns):\n",
    "    dummy_variables = dummy(df, cat_features)\n",
    "    df = pd.concat([df] + dummy_variables, axis=1)\n",
    "    df = df.drop(cat_features, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17029505-1736-4f16-aefe-b446cf91e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(df, columns_to_encode):\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for column in columns_to_encode:\n",
    "        if column in df.columns:\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1260625d-03d7-42fa-b179-177ffc251538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_results(mean_df, std_df):\n",
    "    concatenated_results = []\n",
    "\n",
    "    for index, row_mean in mean_df.iterrows():\n",
    "        classificador = row_mean['Classification']\n",
    "        row_std = std_df.loc[std_df['Classification'] == classificador].squeeze()\n",
    "\n",
    "        accuracy = f\"{row_mean['Accuracy']:.4f} +- {row_std['Accuracy']:.2f}\"\n",
    "        precision = f\"{row_mean['Precision']:.4f} +- {row_std['Precision']:.2f}\"\n",
    "        recall = f\"{row_mean['Recall']:.4f} +- {row_std['Recall']:.2f}\"\n",
    "        f1 = f\"{row_mean['F1 Score']:.4f} +- {row_std['F1 Score']:.2f}\"\n",
    "        roc_auc = f\"{row_mean['ROC/AUC']:.4f} +- {row_std['ROC/AUC']:.2f}\"\n",
    "\n",
    "        concatenated_results.append({\n",
    "            \"Classification\": classificador,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1,\n",
    "            \"ROC/AUC\": roc_auc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(concatenated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3756a2-6aff-4690-94a5-5349b0826983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pipeline(X, y, num_features: list , cat_features: list, sampling_strategy: str, metadata=None, target=None):\n",
    "    print(f\"Sampling Strategy: {sampling_strategy}\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_outer_loop_folds = 5\n",
    "    num_inner_loop_folds = 5\n",
    "    results = []\n",
    "    \n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"Decision Tree\",\n",
    "            DecisionTreeClassifier(),\n",
    "            {\n",
    "                \"model__max_depth\": [None, 1, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"model__n_neighbors\": [1, 3, 5, 7, 10],\n",
    "                \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200, 300],\n",
    "                \"model__max_depth\": [None, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            {\n",
    "                \"model__C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"model__solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"MLP\",\n",
    "            MLPClassifier(max_iter=1000),\n",
    "            {\n",
    "                \"model__hidden_layer_sizes\": [(100,), (100, 50)],\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    standard_scaler = ColumnTransformer(\n",
    "        transformers=[(\"numerical_standard_scaler\", StandardScaler(), num_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    \n",
    " \n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"\\nTraining Model: {model}\")\n",
    "        folds = KFold(n_splits=num_outer_loop_folds, shuffle=True).split(X, y)\n",
    "        for i, (train_index, test_index) in enumerate(folds):\n",
    "            print(f\"Training fold {i+1}...\")\n",
    "       \n",
    "            X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test, y_test = X.iloc[test_index, :], y.iloc[test_index]\n",
    "            \n",
    "            \n",
    "            normalization_step = (\"normalization\", standard_scaler)\n",
    "            model_step = (\"model\", model)\n",
    "            \n",
    "            if sampling_strategy == \"TBTR\":\n",
    "                balance_classes_step = (\"resampling_tbtr\", SDVPipelineTBTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"TSTR\":\n",
    "                balance_classes_step = (\"resampling_tstr\", SDVPipelineTSTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"SMOTE\":\n",
    "                balance_classes_step = (\"resampling_smote\", SMOTE(random_state=42))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"BASELINE\":\n",
    "                steps = [normalization_step, model_step]\n",
    "                \n",
    "            pipeline = Pipeline(steps = steps)\n",
    "\n",
    "            clf = GridSearchCV(pipeline, param_grid, cv=num_inner_loop_folds, n_jobs=-1, return_train_score=False, scoring='accuracy') # scoring = accuracy ou roc_auc?\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classification\": name,\n",
    "                    \"Accuracy\": round(accuracy_test, 4),\n",
    "                    \"Precision\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "    mean_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).mean()\n",
    "    std_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).std()\n",
    "    results_df = mean_std_results(mean_df, std_df)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ae738-0464-4ccc-b31a-6fbfdfdcc85b",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c4d037c-2097-40ba-abab-4f4ad03a0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"repeat_retailer\", \"used_chip\", \"used_pin_number\", \"online_order\"]\n",
    "num_features = [\n",
    "    \"distance_from_home\",\n",
    "    \"distance_from_last_transaction\",\n",
    "    \"ratio_to_median_purchase_price\",\n",
    "]\n",
    "target = \"fraud\"\n",
    "\n",
    "df = pd.read_csv(\"data/card_fraud/card_fraud_original.csv\").sample(1000) # apenas para analisar se o código funciona\n",
    "\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df)\n",
    "metadata.update_column(\n",
    "    column_name=\"distance_from_home\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"distance_from_last_transaction\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"ratio_to_median_purchase_price\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"ratio_to_median_purchase_price\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"fraud\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Int8\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"online_order\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Int8\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"used_pin_number\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Int8\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"used_chip\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Int8\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"repeat_retailer\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Int8\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5c960-a1bf-4441-8342-c7b0af42376a",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7157d72f-372c-4a1a-a2b0-16f591d3c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: BASELINE\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9780 +- 0.01</td>\n",
       "      <td>0.8639 +- 0.14</td>\n",
       "      <td>0.9025 +- 0.03</td>\n",
       "      <td>0.8786 +- 0.08</td>\n",
       "      <td>0.9442 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9740 +- 0.01</td>\n",
       "      <td>0.8225 +- 0.04</td>\n",
       "      <td>0.9322 +- 0.05</td>\n",
       "      <td>0.8727 +- 0.02</td>\n",
       "      <td>0.9556 +- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9600 +- 0.01</td>\n",
       "      <td>0.8942 +- 0.04</td>\n",
       "      <td>0.6439 +- 0.04</td>\n",
       "      <td>0.7481 +- 0.04</td>\n",
       "      <td>0.8181 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9830 +- 0.01</td>\n",
       "      <td>0.9214 +- 0.09</td>\n",
       "      <td>0.8992 +- 0.08</td>\n",
       "      <td>0.9048 +- 0.05</td>\n",
       "      <td>0.9452 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9850 +- 0.01</td>\n",
       "      <td>0.9770 +- 0.03</td>\n",
       "      <td>0.8560 +- 0.16</td>\n",
       "      <td>0.9050 +- 0.10</td>\n",
       "      <td>0.9269 +- 0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9760 +- 0.01</td>\n",
       "      <td>0.8906 +- 0.06</td>\n",
       "      <td>0.8335 +- 0.07</td>\n",
       "      <td>0.8596 +- 0.05</td>\n",
       "      <td>0.9118 +- 0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.9780 +- 0.01  0.8639 +- 0.14  0.9025 +- 0.03   \n",
       "1                  KNN  0.9740 +- 0.01  0.8225 +- 0.04  0.9322 +- 0.05   \n",
       "2  Logistic Regression  0.9600 +- 0.01  0.8942 +- 0.04  0.6439 +- 0.04   \n",
       "3                  MLP  0.9830 +- 0.01  0.9214 +- 0.09  0.8992 +- 0.08   \n",
       "4        Random Forest  0.9850 +- 0.01  0.9770 +- 0.03  0.8560 +- 0.16   \n",
       "5                  SVM  0.9760 +- 0.01  0.8906 +- 0.06  0.8335 +- 0.07   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.8786 +- 0.08  0.9442 +- 0.02  \n",
       "1  0.8727 +- 0.02  0.9556 +- 0.03  \n",
       "2  0.7481 +- 0.04  0.8181 +- 0.02  \n",
       "3  0.9048 +- 0.05  0.9452 +- 0.04  \n",
       "4  0.9050 +- 0.10  0.9269 +- 0.08  \n",
       "5  0.8596 +- 0.05  0.9118 +- 0.03  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"BASELINE\")\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b40ef5-6c8e-4c31-90a1-209b3087489a",
   "metadata": {},
   "source": [
    "## TBTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d2f3ff-ce25-421a-9ea5-869000288ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBTR (Treinar com Dados Balanceados [SDV + Dados Reais] , Testar com Dados Reais)\n",
    "class SDVPipelineTBTR(BaseSampler):\n",
    "    _sampling_type = \"over-sampling\"\n",
    "    \n",
    "    _parameter_constraints = {\n",
    "        \"X\": [pd.DataFrame],\n",
    "        \"y\": [pd.DataFrame, pd.Series],\n",
    "        \"metadata\": [object],\n",
    "        \"target\": [str],\n",
    "        \"num_features\": [list],\n",
    "        \"cat_features\": [list],\n",
    "    }\n",
    "    \n",
    "    def __init__(self, metadata, target, num_features, cat_features):\n",
    "        self.metadata = metadata\n",
    "        self.target = target\n",
    "        self.num_features = num_features\n",
    "        self.cat_features = cat_features\n",
    "        self.synthesizer = SingleTablePreset(self.metadata, name=\"FAST_ML\")\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit_resample(self, X, y):\n",
    "        X = pd.DataFrame(X, columns=self.num_features + self.cat_features).reset_index(drop=True)\n",
    "        y = pd.DataFrame(y, columns=[self.target]).reset_index(drop=True)\n",
    "        df_train = pd.merge(X, y, left_index=True, right_index=True)\n",
    "        for col in self.cat_features:\n",
    "            df_train[col] = df_train[col].astype(int)\n",
    "        \n",
    "        self.synthesizer.fit(df_train)\n",
    "\n",
    "        class_counts = y[self.target].value_counts()\n",
    "        minority_class = class_counts.idxmin()\n",
    "        synthetic_samples_needed = class_counts.max() - class_counts.min()\n",
    "\n",
    "        if minority_class == 0:\n",
    "            balanced_conditions_0 = Condition(\n",
    "                num_rows=synthetic_samples_needed,\n",
    "                column_values={self.target: 0},\n",
    "            )\n",
    "            df_synth = self.synthesizer.sample_from_conditions(\n",
    "                conditions=[balanced_conditions_0]\n",
    "            )\n",
    "        elif minority_class == 1:\n",
    "            balanced_conditions_1 = Condition(\n",
    "                num_rows=synthetic_samples_needed,\n",
    "                column_values={self.target: 1},\n",
    "            )\n",
    "            df_synth = self.synthesizer.sample_from_conditions(\n",
    "                conditions=[balanced_conditions_1]\n",
    "            )\n",
    "        \n",
    "        X_balanced = pd.concat([X, df_synth.drop(self.target, axis=1)], axis=0, ignore_index=True)\n",
    "        y_balanced = pd.concat([y, df_synth[[self.target]]], axis=0, ignore_index=True)\n",
    "              \n",
    "        if sparse.issparse(X):\n",
    "            X_balanced = sparse.vstack([X_balanced], format=X.format)\n",
    "        else:\n",
    "            X_balanced = np.vstack([X_balanced])\n",
    "            \n",
    "        y_balanced = pd.Series(np.ravel(y_balanced))\n",
    "\n",
    "        return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb70d4bb-3981-45f8-9b9c-5c8c38365abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: TBTR\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 666/666 [00:00<00:00, 11288.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 640/640 [00:00<00:00, 10847.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 656/656 [00:00<00:00, 11714.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 642/642 [00:00<00:00, 11068.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 644/644 [00:00<00:00, 11103.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 644/644 [00:00<00:00, 11103.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 652/652 [00:00<00:00, 11241.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 658/658 [00:00<00:00, 11749.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 640/640 [00:00<00:00, 11227.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 654/654 [00:00<00:00, 11473.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 644/644 [00:00<00:00, 11291.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 656/656 [00:00<00:00, 11508.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 652/652 [00:00<00:00, 11847.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 662/662 [00:00<00:00, 8486.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 634/634 [00:00<00:00, 10220.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 652/652 [00:00<00:00, 11437.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 646/646 [00:00<00:00, 11333.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 660/660 [00:00<00:00, 11186.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 648/648 [00:00<00:00, 10124.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 642/642 [00:00<00:00, 11457.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 642/642 [00:00<00:00, 11264.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 650/650 [00:00<00:00, 11206.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 640/640 [00:00<00:00, 11227.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 652/652 [00:00<00:00, 11051.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 664/664 [00:00<00:00, 11857.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 642/642 [00:00<00:00, 11263.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 644/644 [00:00<00:00, 10566.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 670/670 [00:00<00:00, 12408.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 648/648 [00:00<00:00, 11571.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 644/644 [00:00<00:00, 11298.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9100 +- 0.02</td>\n",
       "      <td>0.5200 +- 0.11</td>\n",
       "      <td>0.9172 +- 0.04</td>\n",
       "      <td>0.6569 +- 0.07</td>\n",
       "      <td>0.9134 +- 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9390 +- 0.02</td>\n",
       "      <td>0.6091 +- 0.08</td>\n",
       "      <td>0.9627 +- 0.06</td>\n",
       "      <td>0.7433 +- 0.07</td>\n",
       "      <td>0.9498 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9390 +- 0.01</td>\n",
       "      <td>0.6148 +- 0.10</td>\n",
       "      <td>0.8579 +- 0.09</td>\n",
       "      <td>0.7154 +- 0.10</td>\n",
       "      <td>0.9019 +- 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9430 +- 0.01</td>\n",
       "      <td>0.6193 +- 0.12</td>\n",
       "      <td>0.9548 +- 0.05</td>\n",
       "      <td>0.7470 +- 0.09</td>\n",
       "      <td>0.9483 +- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9510 +- 0.02</td>\n",
       "      <td>0.6741 +- 0.13</td>\n",
       "      <td>0.8774 +- 0.13</td>\n",
       "      <td>0.7619 +- 0.13</td>\n",
       "      <td>0.9172 +- 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9440 +- 0.02</td>\n",
       "      <td>0.6473 +- 0.16</td>\n",
       "      <td>0.9088 +- 0.07</td>\n",
       "      <td>0.7439 +- 0.11</td>\n",
       "      <td>0.9287 +- 0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.9100 +- 0.02  0.5200 +- 0.11  0.9172 +- 0.04   \n",
       "1                  KNN  0.9390 +- 0.02  0.6091 +- 0.08  0.9627 +- 0.06   \n",
       "2  Logistic Regression  0.9390 +- 0.01  0.6148 +- 0.10  0.8579 +- 0.09   \n",
       "3                  MLP  0.9430 +- 0.01  0.6193 +- 0.12  0.9548 +- 0.05   \n",
       "4        Random Forest  0.9510 +- 0.02  0.6741 +- 0.13  0.8774 +- 0.13   \n",
       "5                  SVM  0.9440 +- 0.02  0.6473 +- 0.16  0.9088 +- 0.07   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.6569 +- 0.07  0.9134 +- 0.01  \n",
       "1  0.7433 +- 0.07  0.9498 +- 0.04  \n",
       "2  0.7154 +- 0.10  0.9019 +- 0.05  \n",
       "3  0.7470 +- 0.09  0.9483 +- 0.03  \n",
       "4  0.7619 +- 0.13  0.9172 +- 0.07  \n",
       "5  0.7439 +- 0.11  0.9287 +- 0.03  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbtr_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"TBTR\", metadata = metadata, target = target)\n",
    "tbtr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea05d20-be82-44d8-81d1-fd13cc430dd7",
   "metadata": {},
   "source": [
    "## TSTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08bb5c76-cd10-46b3-942c-d0138653a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSTR (Treinar com Dados Sintéticos, Testar com Dados Reais)\n",
    "# Dados Sintéticos Balanceados\n",
    "class SDVPipelineTSTR(BaseSampler):\n",
    "    _sampling_type = \"over-sampling\"\n",
    "    \n",
    "    _parameter_constraints = {\n",
    "        \"X\": [pd.DataFrame],\n",
    "        \"y\": [pd.DataFrame, pd.Series],\n",
    "        \"metadata\": [object],\n",
    "        \"target\": [str],\n",
    "        \"num_features\": [list],\n",
    "        \"cat_features\": [list],\n",
    "    }\n",
    "    \n",
    "    def __init__(self, metadata, target, num_features, cat_features):\n",
    "        self.metadata = metadata\n",
    "        self.target = target\n",
    "        self.num_features = num_features\n",
    "        self.cat_features = cat_features\n",
    "        self.synthesizer = SingleTablePreset(self.metadata, name=\"FAST_ML\")\n",
    "        super().__init__()\n",
    "        \n",
    "    def _fit_resample(self, X, y):\n",
    "        X = pd.DataFrame(X, columns=self.num_features + self.cat_features).reset_index(drop=True)\n",
    "        y = pd.DataFrame(y, columns=[self.target]).reset_index(drop=True)\n",
    "        df_train = pd.merge(X, y, left_index=True, right_index=True)\n",
    "        for col in self.cat_features:\n",
    "            df_train[col] = df_train[col].astype(int)\n",
    "        \n",
    "        self.synthesizer.fit(df_train)\n",
    "        \n",
    "        class_counts = y.value_counts()\n",
    "        majority_class = class_counts.idxmax()\n",
    "        synthetic_samples_needed = class_counts.max()\n",
    "\n",
    "        balanced_conditions_0 = Condition(\n",
    "            num_rows=synthetic_samples_needed,\n",
    "            column_values={target: 0},\n",
    "        )\n",
    "\n",
    "        balanced_conditions_1 = Condition(\n",
    "            num_rows=synthetic_samples_needed,\n",
    "            column_values={target: 1},\n",
    "        )\n",
    "\n",
    "        df_synth = self.synthesizer.sample_from_conditions(\n",
    "            conditions=[balanced_conditions_0, balanced_conditions_1]\n",
    "        )\n",
    "        \n",
    "        X_train_synth = df_synth.drop(target, axis=1)\n",
    "        y_train_synth = df_synth[target]\n",
    "        \n",
    "        if sparse.issparse(X):\n",
    "            X_train_synth = sparse.vstack([X_train_synth], format=X.format)\n",
    "        else:\n",
    "            X_train_synth = np.vstack([X_train_synth])\n",
    "            \n",
    "        y_train_synth = pd.Series(np.ravel(y_train_synth))\n",
    "\n",
    "        return X_train_synth, y_train_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b848a35f-966e-42c0-aaca-bedac48c16cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: TSTR\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1466/1466 [00:00<00:00, 9773.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1440/1440 [00:00<00:00, 9200.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1456/1456 [00:00<00:00, 9215.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1442/1442 [00:00<00:00, 7589.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1444/1444 [00:00<00:00, 7977.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1444/1444 [00:00<00:00, 10241.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1452/1452 [00:00<00:00, 9810.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1458/1458 [00:00<00:00, 10120.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1440/1440 [00:00<00:00, 8372.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1454/1454 [00:00<00:00, 5769.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1444/1444 [00:00<00:00, 10348.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1456/1456 [00:00<00:00, 10181.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1452/1452 [00:00<00:00, 10014.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1462/1462 [00:00<00:00, 7735.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1434/1434 [00:00<00:00, 10170.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1452/1452 [00:00<00:00, 9810.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1446/1446 [00:00<00:00, 8262.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1460/1460 [00:00<00:00, 8110.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1448/1448 [00:00<00:00, 6188.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1442/1442 [00:00<00:00, 6801.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1448/1448 [00:00<00:00, 6830.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1458/1458 [00:00<00:00, 6749.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1442/1442 [00:00<00:00, 3525.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1452/1452 [00:00<00:00, 6340.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1448/1448 [00:00<00:00, 6766.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1448/1448 [00:00<00:00, 6766.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1444/1444 [00:00<00:00, 6747.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1450/1450 [00:00<00:00, 6223.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1458/1458 [00:00<00:00, 6657.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1448/1448 [00:00<00:00, 6552.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8990 +- 0.02</td>\n",
       "      <td>0.4655 +- 0.16</td>\n",
       "      <td>0.5953 +- 0.19</td>\n",
       "      <td>0.5121 +- 0.16</td>\n",
       "      <td>0.7624 +- 0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9140 +- 0.03</td>\n",
       "      <td>0.5393 +- 0.08</td>\n",
       "      <td>0.7173 +- 0.13</td>\n",
       "      <td>0.6096 +- 0.07</td>\n",
       "      <td>0.8271 +- 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9440 +- 0.02</td>\n",
       "      <td>0.6958 +- 0.10</td>\n",
       "      <td>0.7546 +- 0.12</td>\n",
       "      <td>0.7181 +- 0.08</td>\n",
       "      <td>0.8584 +- 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9490 +- 0.01</td>\n",
       "      <td>0.7265 +- 0.04</td>\n",
       "      <td>0.7287 +- 0.13</td>\n",
       "      <td>0.7212 +- 0.07</td>\n",
       "      <td>0.8500 +- 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9440 +- 0.03</td>\n",
       "      <td>0.7022 +- 0.18</td>\n",
       "      <td>0.7120 +- 0.18</td>\n",
       "      <td>0.7029 +- 0.17</td>\n",
       "      <td>0.8394 +- 0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9440 +- 0.01</td>\n",
       "      <td>0.6799 +- 0.09</td>\n",
       "      <td>0.7419 +- 0.11</td>\n",
       "      <td>0.7042 +- 0.07</td>\n",
       "      <td>0.8539 +- 0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.8990 +- 0.02  0.4655 +- 0.16  0.5953 +- 0.19   \n",
       "1                  KNN  0.9140 +- 0.03  0.5393 +- 0.08  0.7173 +- 0.13   \n",
       "2  Logistic Regression  0.9440 +- 0.02  0.6958 +- 0.10  0.7546 +- 0.12   \n",
       "3                  MLP  0.9490 +- 0.01  0.7265 +- 0.04  0.7287 +- 0.13   \n",
       "4        Random Forest  0.9440 +- 0.03  0.7022 +- 0.18  0.7120 +- 0.18   \n",
       "5                  SVM  0.9440 +- 0.01  0.6799 +- 0.09  0.7419 +- 0.11   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.5121 +- 0.16  0.7624 +- 0.09  \n",
       "1  0.6096 +- 0.07  0.8271 +- 0.07  \n",
       "2  0.7181 +- 0.08  0.8584 +- 0.06  \n",
       "3  0.7212 +- 0.07  0.8500 +- 0.06  \n",
       "4  0.7029 +- 0.17  0.8394 +- 0.10  \n",
       "5  0.7042 +- 0.07  0.8539 +- 0.06  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstr_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"TSTR\", metadata = metadata, target = target)\n",
    "tstr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fca3cf-2fb3-4f2f-af37-be33e97286d2",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538bb055-a694-414d-987c-847f36fdfb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline_smote(X, y, num_features: list , cat_features: list):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_outer_loop_folds = 5\n",
    "    num_inner_loop_folds = 5\n",
    "    results = []\n",
    "    \n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"Decision Tree\",\n",
    "            DecisionTreeClassifier(),\n",
    "            {\n",
    "                \"model__max_depth\": [None, 1, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"model__n_neighbors\": [1, 3, 5, 7, 10],\n",
    "                \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200, 300],\n",
    "                \"model__max_depth\": [None, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            {\n",
    "                \"model__C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"model__solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"MLP\",\n",
    "            MLPClassifier(max_iter=1000),\n",
    "            {\n",
    "                \"model__hidden_layer_sizes\": [(100,), (100, 50)],\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    standard_scaler = ColumnTransformer(\n",
    "        transformers=[(\"numerical_standard_scaler\", StandardScaler(), num_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "        \n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"\\nTraining Model: {model}\")\n",
    "        folds = KFold(n_splits=num_outer_loop_folds, shuffle=True).split(X, y)\n",
    "        for i, (train_index, test_index) in enumerate(folds):\n",
    "            print(f\"Training fold {i+1}...\")\n",
    "       \n",
    "            X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test, y_test = X.iloc[test_index, :], y.iloc[test_index]\n",
    "          \n",
    "            balance_classes_step = (\"balacing\", SMOTE(random_state=42))\n",
    "            normalization_step = (\"normalization\", standard_scaler)\n",
    "            model_step = (\"model\", model)\n",
    "            steps = [balance_classes_step, normalization_step, model_step]\n",
    "            pipeline = Pipeline(steps = steps)\n",
    "\n",
    "            clf = GridSearchCV(pipeline, param_grid, cv=num_inner_loop_folds, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classification\": name,\n",
    "                    \"Accuracy\": round(accuracy_test, 4),\n",
    "                    \"Precision\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "    mean_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).mean()\n",
    "    std_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).std()\n",
    "    results_df = mean_std_results(mean_df, std_df)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc75c205-47c3-4488-b0cd-5da5214553c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: SMOTE\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9780 +- 0.01</td>\n",
       "      <td>0.8481 +- 0.10</td>\n",
       "      <td>0.9337 +- 0.05</td>\n",
       "      <td>0.8862 +- 0.06</td>\n",
       "      <td>0.9580 +- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9690 +- 0.02</td>\n",
       "      <td>0.7811 +- 0.11</td>\n",
       "      <td>0.9513 +- 0.03</td>\n",
       "      <td>0.8549 +- 0.07</td>\n",
       "      <td>0.9613 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9410 +- 0.02</td>\n",
       "      <td>0.6308 +- 0.05</td>\n",
       "      <td>0.9169 +- 0.08</td>\n",
       "      <td>0.7454 +- 0.05</td>\n",
       "      <td>0.9302 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9790 +- 0.01</td>\n",
       "      <td>0.8520 +- 0.09</td>\n",
       "      <td>0.9415 +- 0.04</td>\n",
       "      <td>0.8911 +- 0.04</td>\n",
       "      <td>0.9625 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9820 +- 0.01</td>\n",
       "      <td>0.9058 +- 0.10</td>\n",
       "      <td>0.9318 +- 0.10</td>\n",
       "      <td>0.9117 +- 0.05</td>\n",
       "      <td>0.9592 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9660 +- 0.01</td>\n",
       "      <td>0.7533 +- 0.10</td>\n",
       "      <td>0.9148 +- 0.07</td>\n",
       "      <td>0.8229 +- 0.08</td>\n",
       "      <td>0.9426 +- 0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.9780 +- 0.01  0.8481 +- 0.10  0.9337 +- 0.05   \n",
       "1                  KNN  0.9690 +- 0.02  0.7811 +- 0.11  0.9513 +- 0.03   \n",
       "2  Logistic Regression  0.9410 +- 0.02  0.6308 +- 0.05  0.9169 +- 0.08   \n",
       "3                  MLP  0.9790 +- 0.01  0.8520 +- 0.09  0.9415 +- 0.04   \n",
       "4        Random Forest  0.9820 +- 0.01  0.9058 +- 0.10  0.9318 +- 0.10   \n",
       "5                  SVM  0.9660 +- 0.01  0.7533 +- 0.10  0.9148 +- 0.07   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.8862 +- 0.06  0.9580 +- 0.03  \n",
       "1  0.8549 +- 0.07  0.9613 +- 0.02  \n",
       "2  0.7454 +- 0.05  0.9302 +- 0.04  \n",
       "3  0.8911 +- 0.04  0.9625 +- 0.02  \n",
       "4  0.9117 +- 0.05  0.9592 +- 0.04  \n",
       "5  0.8229 +- 0.08  0.9426 +- 0.04  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"SMOTE\")\n",
    "smote_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de0ba8-4115-44a6-b161-13ea28b74427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5b762-27f2-41b4-a8d1-7f430ace404e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b7213-34eb-4949-92e8-a131cc670a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6338d-b075-4f52-8747-6e466904ce96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c653d-5e15-43cb-856c-b78a6ea5cb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789813d1-851c-4057-8489-fb16b786d541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d7c32-8581-4155-a88b-6ee0d4c16042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc580cc-fe13-41a5-a32c-ec68712d0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### debugs\n",
    "\n",
    "# with open('debug.txt', 'w') as f:\n",
    "#     f.write(f'synthetic_samples_needed: {synthetic_samples_needed}\\n')\n",
    "#     f.write(f'df_synth: {df_synth.shape}\\n')\n",
    "#     f.write(f'X: {X.shape}\\n')\n",
    "#     f.write(f'df_synth.drop(self.target, axis=1): {df_synth.drop(self.target, axis=1).shape}\\n')\n",
    "#     f.write(f'y: {y.shape}\\n')\n",
    "#     f.write(f'df_synth[self.target]: {df_synth[self.target].shape}\\n')\n",
    "#     f.write(f'y_balanced: {y_balanced.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048c307-8014-4d2c-b3a6-21675c5117bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencoder = make_column_transformer(\n",
    "#     (OneHotEncoder(), cat_features),\n",
    "#     remainder='passthrough',\n",
    "# )\n",
    "\n",
    "# onehotencoder_step = (\"encoder\", onehotencoder)\n",
    "# [onehotencoder_step, normalization_step, model_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2f1b9-59bd-48c2-9db6-8ae0c5db562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver a questão do pq do X estar indo pra float, é pra ficar int"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
