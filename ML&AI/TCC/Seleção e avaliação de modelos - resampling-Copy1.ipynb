{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302f1b04-204d-442f-8a53-934e031a4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.manifold import TSNE\n",
    "from imblearn.base import BaseSampler\n",
    "from imblearn.over_sampling.base import BaseOverSampler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "\n",
    "import sdgym\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import (\n",
    "    CTGANSynthesizer,\n",
    "    TVAESynthesizer,\n",
    "    GaussianCopulaSynthesizer,\n",
    "    CopulaGANSynthesizer,\n",
    ")\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.evaluation.single_table import (\n",
    "    evaluate_quality,\n",
    "    get_column_plot,\n",
    "    get_column_pair_plot,\n",
    "    run_diagnostic,\n",
    ")\n",
    "from sdv.sampling import Condition\n",
    "from imblearn.utils import check_target_type\n",
    "from scipy import sparse\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\", font_scale=0.5)\n",
    "custom_palette = [\"#8b4513\", \"#90ee90\", \"#545454\", \"#6a287e\", \"#f0be00\"]\n",
    "sns.set_palette(custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8bbd1-ceaf-4339-9437-4b61aca306b7",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bbce24-efc4-495f-a655-7605696a000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(df, columns):\n",
    "    dummy_variables = []\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(df[column], prefix=column)\n",
    "        dummy_variables.append(dummies)\n",
    "    return dummy_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3084bd82-c3b2-4198-87aa-ee4621466dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_transform(df, columns):\n",
    "    dummy_variables = dummy(df, cat_features)\n",
    "    df = pd.concat([df] + dummy_variables, axis=1)\n",
    "    df = df.drop(cat_features, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17029505-1736-4f16-aefe-b446cf91e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(df, columns_to_encode):\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for column in columns_to_encode:\n",
    "        if column in df.columns:\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1260625d-03d7-42fa-b179-177ffc251538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_results(mean_df, std_df):\n",
    "    concatenated_results = []\n",
    "\n",
    "    for index, row_mean in mean_df.iterrows():\n",
    "        classificador = row_mean['Classification']\n",
    "        row_std = std_df.loc[std_df['Classification'] == classificador].squeeze()\n",
    "\n",
    "        accuracy = f\"{row_mean['Accuracy']:.4f} +- {row_std['Accuracy']:.2f}\"\n",
    "        precision = f\"{row_mean['Precision']:.4f} +- {row_std['Precision']:.2f}\"\n",
    "        recall = f\"{row_mean['Recall']:.4f} +- {row_std['Recall']:.2f}\"\n",
    "        f1 = f\"{row_mean['F1 Score']:.4f} +- {row_std['F1 Score']:.2f}\"\n",
    "        roc_auc = f\"{row_mean['ROC/AUC']:.4f} +- {row_std['ROC/AUC']:.2f}\"\n",
    "\n",
    "        concatenated_results.append({\n",
    "            \"Classification\": classificador,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1,\n",
    "            \"ROC/AUC\": roc_auc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(concatenated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c32e180-425d-4f71-bde6-d45ef321d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pipeline(X, y, num_features: list , cat_features: list, sampling_strategy: str, metadata=None, target=None):\n",
    "    print(f\"Sampling Strategy: {sampling_strategy}\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_outer_loop_folds = 5\n",
    "    num_inner_loop_folds = 5\n",
    "    results = []\n",
    "    \n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"Decision Tree\",\n",
    "            DecisionTreeClassifier(),\n",
    "            {\n",
    "                \"model__max_depth\": [None, 1, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"model__n_neighbors\": [1, 3, 5, 7, 10],\n",
    "                \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200, 300],\n",
    "                \"model__max_depth\": [None, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            {\n",
    "                \"model__C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"model__solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"MLP\",\n",
    "            MLPClassifier(max_iter=1000),\n",
    "            {\n",
    "                \"model__hidden_layer_sizes\": [(100,), (100, 50)],\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    standard_scaler = ColumnTransformer(\n",
    "        transformers=[(\"numerical_standard_scaler\", StandardScaler(), num_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    \n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"\\nTraining Model: {model}\")\n",
    "        folds = KFold(n_splits=num_outer_loop_folds, shuffle=True).split(X, y)\n",
    "        for i, (train_index, test_index) in enumerate(folds):\n",
    "            print(f\"Training fold {i+1}...\")\n",
    "       \n",
    "            X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test, y_test = X.iloc[test_index, :], y.iloc[test_index]\n",
    "            \n",
    "            X_train.to_csv(\"X_train.csv\", index = False)\n",
    "            X_test.to_csv(\"X_test.csv\", index = False)\n",
    "              \n",
    "            normalization_step = (\"normalization\", standard_scaler)\n",
    "            model_step = (\"model\", model)\n",
    "            \n",
    "            if sampling_strategy == \"TBTR\":\n",
    "                balance_classes_step = (\"resampling_tbtr\", SDVPipelineTBTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"TSTR\":\n",
    "                balance_classes_step = (\"resampling_tstr\", SDVPipelineTSTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"SMOTE\":\n",
    "                balance_classes_step = (\"resampling_smote\", SMOTE(random_state=42))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"BASELINE\":\n",
    "                steps = [normalization_step, model_step]\n",
    "                \n",
    "            pipeline = Pipeline(steps = steps)\n",
    "\n",
    "            clf = GridSearchCV(pipeline, param_grid, cv=num_inner_loop_folds, n_jobs=-1, scoring='accuracy') # scoring = accuracy ou roc_auc?\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classification\": name,\n",
    "                    \"Accuracy\": round(accuracy_test, 4),\n",
    "                    \"Precision\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "        \n",
    "            X_balanced = clf.best_estimator_.named_steps['resampling_tbtr'].X_balanced\n",
    "            y_balanced = clf.best_estimator_.named_steps['resampling_tbtr'].y_balanced\n",
    "                \n",
    "            with open('debug_test.txt', 'w') as f:\n",
    "                f.write(f'X_balanced: {X_balanced.shape}\\n')\n",
    "                f.write(f'y_balanced: {y_balanced.shape}\\n')\n",
    "                f.write(f'X_test: \\n{X_test.shape}\\n')\n",
    "                f.write(f'y_test: {y_test.shape}\\n')\n",
    "                f.write(f'y_test distribution: \\n{y_test.value_counts()}\\n')\n",
    "                f.write(f'y_balanced distribution: \\n{y_balanced.value_counts()}\\n')\n",
    "        \n",
    "    mean_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).mean()\n",
    "    std_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).std()\n",
    "    results_df = mean_std_results(mean_df, std_df)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c3756a2-6aff-4690-94a5-5349b0826983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pipeline(X, y, num_features: list , cat_features: list, sampling_strategy: str, metadata=None, target=None):\n",
    "    print(f\"Sampling Strategy: {sampling_strategy}\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_outer_loop_folds = 5\n",
    "    num_inner_loop_folds = 5\n",
    "    results = []\n",
    "    \n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"Decision Tree\",\n",
    "            DecisionTreeClassifier(),\n",
    "            {\n",
    "                \"model__max_depth\": [None, 1, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"model__n_neighbors\": [1, 3, 5, 7, 10],\n",
    "                \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200, 300],\n",
    "                \"model__max_depth\": [None, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            {\n",
    "                \"model__C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"model__solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"MLP\",\n",
    "            MLPClassifier(max_iter=1000),\n",
    "            {\n",
    "                \"model__hidden_layer_sizes\": [(100,), (100, 50)],\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    standard_scaler = ColumnTransformer(\n",
    "        transformers=[(\"numerical_standard_scaler\", StandardScaler(), num_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    \n",
    "    categorical_encoder = ColumnTransformer(\n",
    "        transformers=[(\"categorical_onehotencoder\", OneHotEncoder(), cat_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    \n",
    "\n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"\\nTraining Model: {model}\")\n",
    "        folds = KFold(n_splits=num_outer_loop_folds, shuffle=True).split(X, y)\n",
    "        for i, (train_index, test_index) in enumerate(folds):\n",
    "            print(f\"Training fold {i+1}...\")\n",
    "       \n",
    "            X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test, y_test = X.iloc[test_index, :], y.iloc[test_index]\n",
    "                     \n",
    "            onehotencoder_step = (\"encoder\", categorical_encoder)\n",
    "            normalization_step = (\"normalization\", standard_scaler)\n",
    "            model_step = (\"model\", model)\n",
    "            \n",
    "            if sampling_strategy == \"TBTR\":\n",
    "                balance_classes_step = (\"resampling_tbtr\", SDVPipelineTBTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"TSTR\":\n",
    "                balance_classes_step = (\"resampling_tstr\", SDVPipelineTSTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"SMOTE\":\n",
    "                balance_classes_step = (\"resampling_smote\", SMOTE(random_state=42))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"BASELINE\":\n",
    "                steps = [onehotencoder_step, normalization_step, model_step]\n",
    "                \n",
    "            pipeline = Pipeline(steps = steps)\n",
    "\n",
    "            clf = GridSearchCV(pipeline, param_grid, cv=num_inner_loop_folds, n_jobs=-1, scoring='accuracy') # scoring = accuracy ou roc_auc?\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classification\": name,\n",
    "                    \"Accuracy\": round(accuracy_test, 4),\n",
    "                    \"Precision\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "                \n",
    "    mean_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).mean()\n",
    "    std_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).std()\n",
    "    results_df = mean_std_results(mean_df, std_df)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a9c1c-6c2c-4c14-adf5-3715ea4f23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_pipeline(X, y, num_features: list , cat_features: list, sampling_strategy: str, metadata=None, target=None):\n",
    "    print(f\"Sampling Strategy: {sampling_strategy}\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_outer_loop_folds = 5\n",
    "    num_inner_loop_folds = 5\n",
    "    results = []\n",
    "    \n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    standard_scaler = ColumnTransformer(\n",
    "        transformers=[(\"numerical_standard_scaler\", StandardScaler(), num_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    \n",
    "    categorical_encoder = ColumnTransformer(\n",
    "        transformers=[(\"categorical_onehotencoder\", OneHotEncoder(), cat_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    \n",
    "\n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"\\nTraining Model: {model}\")\n",
    "        folds = KFold(n_splits=num_outer_loop_folds, shuffle=True).split(X, y)\n",
    "        for i, (train_index, test_index) in enumerate(folds):\n",
    "            print(f\"Training fold {i+1}...\")\n",
    "       \n",
    "            X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test, y_test = X.iloc[test_index, :], y.iloc[test_index]\n",
    "                     \n",
    "            onehotencoder_step = (\"encoder\", categorical_encoder)\n",
    "            normalization_step = (\"normalization\", standard_scaler)\n",
    "            model_step = (\"model\", model)\n",
    "            \n",
    "            if sampling_strategy == \"TBTR\":\n",
    "                balance_classes_step = (\"resampling_tbtr\", SDVPipelineTBTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"TSTR\":\n",
    "                balance_classes_step = (\"resampling_tstr\", SDVPipelineTSTR(metadata = metadata, target = target, num_features = num_features, cat_features = cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"SMOTE\":\n",
    "                balance_classes_step = (\"resampling_smote\", SMOTE(random_state=42))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"BASELINE\":\n",
    "                steps = [onehotencoder_step, normalization_step, model_step]\n",
    "                \n",
    "            pipeline = Pipeline(steps = steps)\n",
    "\n",
    "            clf = GridSearchCV(pipeline, param_grid, cv=num_inner_loop_folds, n_jobs=-1, scoring='accuracy') # scoring = accuracy ou roc_auc?\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classification\": name,\n",
    "                    \"Accuracy\": round(accuracy_test, 4),\n",
    "                    \"Precision\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "                \n",
    "    mean_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).mean()\n",
    "    std_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).std()\n",
    "    results_df = mean_std_results(mean_df, std_df)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b34e289f-2366-42df-a6ab-a0f008292495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def evaluation_pipeline(X, y, num_features: list, cat_features: list, sampling_strategy: str, metadata=None, target=None):\n",
    "    print(f\"Sampling Strategy: {sampling_strategy}\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_outer_loop_folds = 5\n",
    "    num_inner_loop_folds = 5\n",
    "    results = []\n",
    "\n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"Decision Tree\",\n",
    "            DecisionTreeClassifier(),\n",
    "            {\n",
    "                \"model__max_depth\": [None, 1, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"model__n_neighbors\": [1, 3, 5, 7, 10],\n",
    "                \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200, 300],\n",
    "                \"model__max_depth\": [None, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            {\n",
    "                \"model__C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"model__solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"MLP\",\n",
    "            MLPClassifier(max_iter=1000),\n",
    "            {\n",
    "                \"model__hidden_layer_sizes\": [(100,), (100, 50)],\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    num_transformer = (\"numerical_standard_scaler\", StandardScaler(), num_features)\n",
    "    cat_transformer = (\"categorical_onehot\", OneHotEncoder(), cat_features)\n",
    "    transformers = [num_transformer, cat_transformer]\n",
    "\n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"\\nTraining Model: {model}\")\n",
    "        folds = KFold(n_splits=num_outer_loop_folds, shuffle=True).split(X, y)\n",
    "        for i, (train_index, test_index) in enumerate(folds):\n",
    "            print(f\"Training fold {i + 1}...\")\n",
    "\n",
    "            X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test, y_test = X.iloc[test_index, :], y.iloc[test_index]\n",
    "\n",
    "            normalization_step = (\"normalization\", ColumnTransformer(transformers=transformers, remainder=\"passthrough\"))\n",
    "            model_step = (\"model\", model)\n",
    "\n",
    "            if sampling_strategy == \"TBTR\":\n",
    "                balance_classes_step = (\"resampling_tbtr\", SDVPipelineTBTR(metadata=metadata, target=target, num_features=num_features, cat_features=cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"TSTR\":\n",
    "                balance_classes_step = (\"resampling_tstr\", SDVPipelineTSTR(metadata=metadata, target=target, num_features=num_features, cat_features=cat_features))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"SMOTE\":\n",
    "                balance_classes_step = (\"resampling_smote\", SMOTE(random_state=42))\n",
    "                steps = [balance_classes_step, normalization_step, model_step]\n",
    "            elif sampling_strategy == \"BASELINE\":\n",
    "                steps = [normalization_step, model_step]\n",
    "\n",
    "            pipeline = Pipeline(steps=steps)\n",
    "            \n",
    "            X_train_transformed = pipeline.named_steps['normalization'].fit_transform(X_train)\n",
    "            print(f\"Transformed data before training:\\n{X_train_transformed}\")\n",
    "\n",
    "            clf = GridSearchCV(pipeline, param_grid, cv=num_inner_loop_folds, n_jobs=-1, scoring='accuracy')  # scoring = accuracy ou roc_auc?\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            X_test_transformed = pipeline.named_steps['normalization'].fit_transform(X_test)\n",
    "            print(f\"Transformed data after training:\\n{X_test_transformed}\")\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classification\": name,\n",
    "                    \"Accuracy\": round(accuracy_test, 4),\n",
    "                    \"Precision\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            with open('debug_test.txt', 'w') as f:\n",
    "                f.write(f'X_test: \\n{X_test.shape}\\n')\n",
    "                f.write(f'y_test: {y_test.shape}\\n')\n",
    "                f.write(f'y_test distribution: \\n{y_test.value_counts()}\\n')\n",
    "\n",
    "    mean_df = pd.DataFrame(results).groupby([\"Classification\"], as_index=False).mean()\n",
    "    std_df = pd.DataFrame(results).groupby([\"Classification\"], as_index=False).std()\n",
    "    results_df = mean_std_results(mean_df, std_df)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ae738-0464-4ccc-b31a-6fbfdfdcc85b",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c4d037c-2097-40ba-abab-4f4ad03a0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"repeat_retailer\", \"used_chip\", \"used_pin_number\", \"online_order\"]\n",
    "num_features = [\n",
    "    \"distance_from_home\",\n",
    "    \"distance_from_last_transaction\",\n",
    "    \"ratio_to_median_purchase_price\",\n",
    "]\n",
    "target = \"fraud\"\n",
    "\n",
    "df = pd.read_csv(\"data/card_fraud/card_fraud_original.csv\").sample(1000) # apenas para analisar se o c√≥digo funciona\n",
    "# df = dummy_transform(df, cat_features)\n",
    "\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df)\n",
    "metadata.update_column(\n",
    "    column_name=\"distance_from_home\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"distance_from_last_transaction\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"ratio_to_median_purchase_price\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"ratio_to_median_purchase_price\",\n",
    "    sdtype=\"numerical\",\n",
    "    computer_representation=\"Float\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"fraud\",\n",
    "    sdtype=\"categorical\"\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"online_order\",\n",
    "    sdtype=\"categorical\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"used_pin_number\",\n",
    "    sdtype=\"categorical\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"used_chip\",\n",
    "    sdtype=\"categorical\",\n",
    ")\n",
    "\n",
    "metadata.update_column(\n",
    "    column_name=\"repeat_retailer\",\n",
    "    sdtype=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5c960-a1bf-4441-8342-c7b0af42376a",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08854ebd-e4b7-4601-ba3b-d642e702527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: BASELINE\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n",
      "Transformed data before training:\n",
      "[[-0.23842126 -0.24237446  0.68180842 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.27230101  0.21117599  1.07425408 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.41270388 -0.21448779 -0.31162592 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.16862596 -0.18749428 -0.57620135 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.04337145 -0.25388811  0.38075105 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.8061746  -0.26400213 -0.18894016 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.21166344 -0.33762947 -0.49941286 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.21278516 -0.34067606 -0.40718626 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.9442208  -0.29182961  0.40032815 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 2.78030359  1.71907593 -0.45520773 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.48150074 -0.2481489   0.08994409 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.25192411 -0.30419872  2.19945639 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 2...\n",
      "Transformed data before training:\n",
      "[[-0.30871038  0.24065804  1.23567589 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.09375205 -0.25392454 -0.57004662 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.30492228  0.23768361 -0.38786858 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.18233431 -0.19541242 -0.62724469 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.2376048  -0.24849916  2.24467356 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.89234954 -0.27909764 -0.19013089 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.18619523 -0.25735474  0.49667146 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.32641519 -0.23377648 -0.26529448 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.22203803 -0.2550756  -0.31675633 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.13531351 -0.27104167 -0.42803875 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.05357682 -0.23702423 10.96802688 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.04052252 -0.26708957  0.26575991 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 3...\n",
      "Transformed data before training:\n",
      "[[-0.23440643 -0.25518547  0.70753327 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.26680071  0.18822119  1.10053872 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.40104756 -0.2279225  -0.28731813 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.15479367 -0.2015327  -0.55227095 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.03503099 -0.26644162  0.40604646 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.20575186 -0.24898092  1.99573582 ...  0.          0.\n",
      "   1.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.2135092  -0.2798861  -0.3359534  ...  1.          1.\n",
      "   0.        ]\n",
      " [ 1.03837423 -0.28228891 -0.26351887 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.40416291 -0.2817896  -0.02935366 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 2.32066542 -0.09713235 -0.43955228 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.2649801   0.14279215 -0.16145675 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.30630777 -0.28935145 -0.26062453 ...  0.          1.\n",
      "   0.        ]]\n",
      "Training fold 4...\n",
      "Transformed data before training:\n",
      "[[-0.24636838 -0.28532871  0.70615587 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.28311143  0.24294264  1.10425933 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.43538024 -0.25284782 -0.30160058 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.05923963 -0.29873921  0.40075823 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.21386709 -0.27793666  2.01106879 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.88650997 -0.31051947 -0.17714609 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-2.79424987e-01  1.43357101e-01 -3.82499523e-01 ...  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00]\n",
      " [-3.50863815e-01 -9.99256496e-02  8.49397299e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-3.89890926e-01  1.36700148e+01 -3.57171453e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 8.24394023e-02 -1.93305101e-01 -5.64349019e-02 ...  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00]\n",
      " [ 4.40426161e-03 -1.91656396e-01 -2.49584441e-01 ...  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-3.69886677e-02 -2.07980660e-01  4.21662782e-01 ...  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00]]\n",
      "Training fold 5...\n",
      "Transformed data before training:\n",
      "[[-0.24823992 -0.24177989  0.64259777 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.42084813 -0.21550493 -0.31020429 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.29236175 -0.23924009 -0.37455489 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.0308455  -0.25262812  0.35385389 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.21855929 -0.23580019  1.87635193 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.78632009 -0.2621576  -0.19253648 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.28406117  0.49415913  1.68005316 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.05173849 -0.43113497 -0.61871732 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.03379407 -0.47565406  0.94921168 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.40420497 -0.46634366  6.17825316 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.23687135 -0.47890518 -0.52175423 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.24665015 -0.32166706 -0.69153318 ...  0.          0.\n",
      "   1.        ]]\n",
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n",
      "Transformed data before training:\n",
      "[[-0.26257975 -0.24161642  0.69373905 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.4453218  -0.2148372  -0.29505116 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.30929198 -0.23902787 -0.36183233 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.03289078 -0.25267284  0.39408907 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.23115658 -0.23552196  1.97409317 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.8327193  -0.2623852  -0.17293893 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.22284594  0.34665583  1.18383549 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.23850005 -0.3910766  -0.51407818 ...  1.          1.\n",
      "   0.        ]\n",
      " [-0.27220965  4.02212395 -0.61874329 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.0405227  -0.3221249   0.47652243 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.3389979   0.94261469 -0.57504007 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.04684371 -0.3948975   0.45559682 ...  0.          1.\n",
      "   0.        ]]\n",
      "Training fold 2...\n",
      "Transformed data before training:\n",
      "[[-0.23070591 -0.24478423  0.6979439  ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.2636254   0.207303    1.09475425 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.40004879 -0.21698753 -0.30653919 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.16480425 -0.19008111 -0.57405716 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.04309987 -0.25626075  0.39353824 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.78428266 -0.26634213 -0.18248895 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[ 0.85096178 -0.3211865  -0.18435626 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.19994011 -0.21477341 -0.21287699 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 4.05599411 -0.2965762  -0.49956001 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.57560902 -0.33137913  0.85558091 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.18817691 -0.30254943 -0.03290107 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.30816303 -0.29443566  2.05600941 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 3...\n",
      "Transformed data before training:\n",
      "[[-0.23913521 -0.24561617  0.76954186 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.27417678  0.18162903  1.19916001 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.28521278 -0.24307691 -0.39144072 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.02235076 -0.26465846  0.48451854 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.18187065 -0.19391896 -0.6076267  ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.20813897 -0.23963777  2.17775438 ...  0.          0.\n",
      "   1.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.44770962 -0.34585144 -0.28442029 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.30595176  0.52654899 -0.32726606 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.18719911 -0.43340609 -0.2409289  ...  1.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.44495146 -0.29045324 -0.00176239 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.00187528 -0.42712182  0.28063497 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.75382294 -0.44798383 -0.1842953  ...  0.          1.\n",
      "   0.        ]]\n",
      "Training fold 4...\n",
      "Transformed data before training:\n",
      "[[-0.25392818 -0.32577348  0.70537881 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.29373812  0.39716103  1.10315652 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.45871658 -0.28132367 -0.30155304 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.07718849 -0.34412562  0.40023106 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.21871405 -0.31565753  2.00922398 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.97350987 -0.36024681 -0.17720038 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.28213538 -0.23627127 -0.39795731 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.17295878 -0.08959725 -0.13688786 ...  1.          0.\n",
      "   1.        ]\n",
      " [-0.28301986 -0.22402189 -0.60784843 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.34748911 -0.24672929  4.30955077 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.98337919 -0.16894181 -0.37233339 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.33849121 -0.25020403  0.0159394  ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 5...\n",
      "Transformed data before training:\n",
      "[[-0.28409914  0.16669529  1.03946752 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.41555841 -0.23340923 -0.31565877 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.29408955 -0.25708768 -0.38126472 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.01146515 -0.27044373  0.36135384 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.22431795 -0.25365601  1.91355273 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.72567812 -0.27995045 -0.1956955  ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.28952012 -0.29705883  0.96067116 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.07462505 -0.29397812 -0.5372462  ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.14010581 -0.34709981 -0.51233428 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.14480851 -0.33302938 -0.53511423 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.27733166 -0.3458497  -0.45352579 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.64189271 -0.1751117  -0.60011727 ...  0.          0.\n",
      "   1.        ]]\n",
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n",
      "Transformed data before training:\n",
      "[[-0.23955567 -0.24535599  0.76301194 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.27391016  0.2118647   1.17972891 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.41628044 -0.21724366 -0.29186265 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.17319535 -0.19003172 -0.57280109 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.0461857  -0.25696282  0.44333528 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.81967771 -0.26715868 -0.16158923 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.10726803 -0.29291287 -0.55242711 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.33083291 -0.31420519 -0.483701   ...  1.          1.\n",
      "   0.        ]\n",
      " [-0.30946095  0.20654972 -0.40973611 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.27128147 -0.31885466 -0.49276997 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.00737825 -0.31691795  0.28477214 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.24500529 -0.2874008   1.65220329 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 2...\n",
      "Transformed data before training:\n",
      "[[-0.2328282  -0.33139774  0.73483128 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.26547603  0.33535398  1.1567107  ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.40077363 -0.29040234 -0.3331115  ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.0387181  -0.34832364  0.41119434 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.20394935 -0.32206794  2.11767762 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.77378456 -0.36319197 -0.2012242  ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-4.15828828e-01 -1.96686935e-01 -2.87816284e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-2.54316631e-01 -2.11531668e-01 -3.95719401e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [-1.18517080e-02 -2.10265165e-01  5.16272420e-01 ...  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 2.12237010e+00 -1.26513557e-01 -2.66573654e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 9.25181858e-02 -1.97289793e-01 -1.64833261e-01 ...  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 8.78615580e-02 -1.84118035e-01  1.22396340e+01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]]\n",
      "Training fold 3...\n",
      "Transformed data before training:\n",
      "[[-0.26289035 -0.2443879   0.68989648 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.30770488  0.18200923  1.07955156 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.49342313 -0.21817076 -0.29647382 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.4897221  -0.19292132  0.04741149 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.22324938 -0.23842136  1.96711712 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.11885154 -0.26472076 -0.17466044 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[ 0.10640859  0.1364944  -0.14560452 ...  1.          0.\n",
      "   1.        ]\n",
      " [ 0.29817812 -0.46115911 -0.22134907 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.33468658 -0.15878937  0.9428393  ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.22144086 -0.46080215 -0.59650244 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.00171902 -0.30841121 -0.65566957 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.0817677  -0.45077916  0.4250106  ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 4...\n",
      "Transformed data before training:\n",
      "[[-0.24845272 -0.24547773  0.65852047 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.41508499 -0.2183597  -0.30438391 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.291047   -0.24285643 -0.3694168  ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.02097036 -0.25667404  0.36671512 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.21979968 -0.23930617  1.90535582 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.75028934 -0.26650928 -0.18546849 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.32003828  0.31300022  1.48415458 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.40436576  3.58277936 -0.63513387 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.46924872 -0.29484459  0.49386673 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.51845939  0.84317864 -0.58375208 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 4.05831165  2.1229844  -0.53456251 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.54116322 -0.24232473  0.12075785 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 5...\n",
      "Transformed data before training:\n",
      "[[-0.29452725  0.18628633  1.06763221 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.30492874 -0.24169801 -0.37830073 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.10636731 -0.24294078 -0.52439517 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.13529998 -0.1921606  -0.57482423 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.01319858 -0.25518647  0.37749027 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.23228625 -0.23823232  1.95722178 ...  0.          0.\n",
      "   1.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.17824528 -0.3786977   0.82178396 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.41411644 -0.32823465 -0.28862666 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.24017116 -0.33457736 -0.59204252 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.24492396 -0.25298947  0.42572353 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.34257852 -0.41845524  0.08681435 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.23549314 -0.41783464 -0.15149472 ...  0.          1.\n",
      "   0.        ]]\n",
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n",
      "Transformed data before training:\n",
      "[[-0.25397545 -0.28276691  0.63740254 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.06230563 -0.28115481 -0.5172429  ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.44005454  0.02230418 -0.13375003 ...  1.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.08542028 -0.29615476  0.3494837  ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.21788085 -0.27538734  1.86763144 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.00415281 -0.30791513 -0.19534544 ...  0.          1.\n",
      "   0.        ]]\n",
      "Transformed data after training:\n",
      "[[-0.27976707  0.14044916  1.75201902 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.37918122 -0.17794799 -0.30003603 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.28732217 -0.19679095 -0.3993825  ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.04251977 -0.19755693 -0.18551604 ...  1.          0.\n",
      "   1.        ]\n",
      " [-0.21099866 -0.21091584 -0.61421181 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.37720007 -0.15785866  0.21279724 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 2...\n",
      "Transformed data before training:\n",
      "[[-0.24665419 -0.26428912  0.68974742 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.28069543  0.28832307  1.07952279 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.42176751 -0.23031162 -0.2969274  ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.05278449 -0.23499179 14.24917588 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.4189562  -0.19758825  0.04706408 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.80292066 -0.29064058 -0.17507642 ...  0.          1.\n",
      "   0.        ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m baseline_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBASELINE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m baseline_df\n",
      "Cell \u001b[1;32mIn[18], line 106\u001b[0m, in \u001b[0;36mevaluation_pipeline\u001b[1;34m(X, y, num_features, cat_features, sampling_strategy, metadata, target)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformed data before training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mX_train_transformed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39mnum_inner_loop_folds, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# scoring = accuracy ou roc_auc?\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalization\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfit_transform(X_test)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformed data after training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mX_test_transformed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:960\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    955\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabort_everything\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[0;32m    959\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n\u001b[1;32m--> 960\u001b[0m     \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabort_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:565\u001b[0m, in \u001b[0;36mLokyBackend.abort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_ready:\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:494\u001b[0m, in \u001b[0;36mLokyBackend.configure\u001b[1;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FallbackToBackend(\n\u001b[0;32m    492\u001b[0m         SequentialBackend(nesting_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnesting_level))\n\u001b[1;32m--> 494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m get_memmapping_executor(\n\u001b[0;32m    495\u001b[0m     n_jobs, timeout\u001b[38;5;241m=\u001b[39midle_worker_timeout,\n\u001b[0;32m    496\u001b[0m     env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_worker_env(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs),\n\u001b[0;32m    497\u001b[0m     context_id\u001b[38;5;241m=\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmemmappingexecutor_args)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel \u001b[38;5;241m=\u001b[39m parallel\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_jobs\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\executor.py:20\u001b[0m, in \u001b[0;36mget_memmapping_executor\u001b[1;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_memmapping_executor\u001b[39m(n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MemmappingExecutor\u001b[38;5;241m.\u001b[39mget_memmapping_executor(n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\executor.py:52\u001b[0m, in \u001b[0;36mMemmappingExecutor.get_memmapping_executor\u001b[1;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# reducers access the temporary folder in which to store temporary\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# pickles through a call to manager.resolve_temp_folder_name. resolving\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# the folder name dynamically is useful to use different folders across\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# calls of a same reusable executor\u001b[39;00m\n\u001b[0;32m     48\u001b[0m job_reducers, result_reducers \u001b[38;5;241m=\u001b[39m get_memmapping_reducers(\n\u001b[0;32m     49\u001b[0m     unlink_on_gc_collect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     temp_folder_resolver\u001b[38;5;241m=\u001b[39mmanager\u001b[38;5;241m.\u001b[39mresolve_temp_folder_name,\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbackend_args)\n\u001b[1;32m---> 52\u001b[0m _executor, executor_is_reused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reusable_executor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_reducers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_reducers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_reducers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_reducers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreuse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m executor_is_reused:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Only set a _temp_folder_manager for new executors. Reused\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# executors already have a _temporary_folder_manager that must not\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# be re-assigned like that because it is referenced in various\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# places in the reducing machinery of the executor.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     _executor\u001b[38;5;241m.\u001b[39m_temp_folder_manager \u001b[38;5;241m=\u001b[39m manager\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:163\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.get_reusable_executor\u001b[1;34m(cls, max_workers, context, timeout, kill_workers, reuse, job_reducers, result_reducers, initializer, initargs, env)\u001b[0m\n\u001b[0;32m    161\u001b[0m     _executor \u001b[38;5;241m=\u001b[39m executor \u001b[38;5;241m=\u001b[39m _executor_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# Recursive call to build a new instance\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_reusable_executor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers,\n\u001b[0;32m    164\u001b[0m                                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     mp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReusing existing executor with max_workers=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(executor\u001b[38;5;241m.\u001b[39m_max_workers)\n\u001b[0;32m    169\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:142\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.get_reusable_executor\u001b[1;34m(cls, max_workers, context, timeout, kill_workers, reuse, job_reducers, result_reducers, initializer, initargs, env)\u001b[0m\n\u001b[0;32m    140\u001b[0m     executor_id \u001b[38;5;241m=\u001b[39m _get_next_executor_id()\n\u001b[0;32m    141\u001b[0m     _executor_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m--> 142\u001b[0m     _executor \u001b[38;5;241m=\u001b[39m executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    143\u001b[0m         _executor_lock, max_workers\u001b[38;5;241m=\u001b[39mmax_workers,\n\u001b[0;32m    144\u001b[0m         executor_id\u001b[38;5;241m=\u001b[39mexecutor_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reuse \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:98\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.__init__\u001b[1;34m(self, submit_resize_lock, max_workers, context, timeout, executor_id, job_reducers, result_reducers, initializer, initargs, env)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, submit_resize_lock, max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     95\u001b[0m              timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, executor_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, job_reducers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     96\u001b[0m              result_reducers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initargs\u001b[38;5;241m=\u001b[39m(),\n\u001b[0;32m     97\u001b[0m              env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_ReusablePoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_reducers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_reducers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_reducers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_reducers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor_id \u001b[38;5;241m=\u001b[39m executor_id\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock \u001b[38;5;241m=\u001b[39m submit_resize_lock\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:982\u001b[0m, in \u001b[0;36mProcessPoolExecutor.__init__\u001b[1;34m(self, max_workers, job_reducers, result_reducers, timeout, context, initializer, initargs, env)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context \u001b[38;5;241m=\u001b[39m context\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env \u001b[38;5;241m=\u001b[39m env\n\u001b[1;32m--> 982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initializer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initargs \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_initializer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    985\u001b[0m _check_max_depth(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context)\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_reducers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\initializers.py:77\u001b[0m, in \u001b[0;36m_prepare_initializer\u001b[1;34m(initializer, initargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitializer must be a callable, got: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(initializer)\n\u001b[0;32m     71\u001b[0m     )\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Introspect runtime to determine if we need to propagate the viztracer\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# profiler information to the workers:\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_initializers([\n\u001b[0;32m     76\u001b[0m     (initializer, initargs),\n\u001b[1;32m---> 77\u001b[0m     \u001b[43m_make_viztracer_initializer_and_initargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     78\u001b[0m ])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\initializers.py:14\u001b[0m, in \u001b[0;36m_make_viztracer_initializer_and_initargs\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_viztracer_initializer_and_initargs\u001b[39m():\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mviztracer\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         tracer \u001b[38;5;241m=\u001b[39m viztracer\u001b[38;5;241m.\u001b[39mget_tracer()\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tracer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(tracer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;66;03m# Profiler is active: introspect its configuration to\u001b[39;00m\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;66;03m# initialize the workers with the same configuration.\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseline_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"BASELINE\")\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7157d72f-372c-4a1a-a2b0-16f591d3c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: BASELINE\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9780 +- 0.01</td>\n",
       "      <td>0.8639 +- 0.14</td>\n",
       "      <td>0.9025 +- 0.03</td>\n",
       "      <td>0.8786 +- 0.08</td>\n",
       "      <td>0.9442 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9740 +- 0.01</td>\n",
       "      <td>0.8225 +- 0.04</td>\n",
       "      <td>0.9322 +- 0.05</td>\n",
       "      <td>0.8727 +- 0.02</td>\n",
       "      <td>0.9556 +- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9600 +- 0.01</td>\n",
       "      <td>0.8942 +- 0.04</td>\n",
       "      <td>0.6439 +- 0.04</td>\n",
       "      <td>0.7481 +- 0.04</td>\n",
       "      <td>0.8181 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9830 +- 0.01</td>\n",
       "      <td>0.9214 +- 0.09</td>\n",
       "      <td>0.8992 +- 0.08</td>\n",
       "      <td>0.9048 +- 0.05</td>\n",
       "      <td>0.9452 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9850 +- 0.01</td>\n",
       "      <td>0.9770 +- 0.03</td>\n",
       "      <td>0.8560 +- 0.16</td>\n",
       "      <td>0.9050 +- 0.10</td>\n",
       "      <td>0.9269 +- 0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9760 +- 0.01</td>\n",
       "      <td>0.8906 +- 0.06</td>\n",
       "      <td>0.8335 +- 0.07</td>\n",
       "      <td>0.8596 +- 0.05</td>\n",
       "      <td>0.9118 +- 0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.9780 +- 0.01  0.8639 +- 0.14  0.9025 +- 0.03   \n",
       "1                  KNN  0.9740 +- 0.01  0.8225 +- 0.04  0.9322 +- 0.05   \n",
       "2  Logistic Regression  0.9600 +- 0.01  0.8942 +- 0.04  0.6439 +- 0.04   \n",
       "3                  MLP  0.9830 +- 0.01  0.9214 +- 0.09  0.8992 +- 0.08   \n",
       "4        Random Forest  0.9850 +- 0.01  0.9770 +- 0.03  0.8560 +- 0.16   \n",
       "5                  SVM  0.9760 +- 0.01  0.8906 +- 0.06  0.8335 +- 0.07   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.8786 +- 0.08  0.9442 +- 0.02  \n",
       "1  0.8727 +- 0.02  0.9556 +- 0.03  \n",
       "2  0.7481 +- 0.04  0.8181 +- 0.02  \n",
       "3  0.9048 +- 0.05  0.9452 +- 0.04  \n",
       "4  0.9050 +- 0.10  0.9269 +- 0.08  \n",
       "5  0.8596 +- 0.05  0.9118 +- 0.03  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"BASELINE\")\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b40ef5-6c8e-4c31-90a1-209b3087489a",
   "metadata": {},
   "source": [
    "## TBTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d2f3ff-ce25-421a-9ea5-869000288ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBTR (Treinar com Dados Balanceados [SDV + Dados Reais] , Testar com Dados Reais)\n",
    "class SDVPipelineTBTR(BaseSampler):\n",
    "    _sampling_type = \"over-sampling\"\n",
    "    \n",
    "    _parameter_constraints = {\n",
    "        \"X\": [pd.DataFrame],\n",
    "        \"y\": [pd.DataFrame, pd.Series],\n",
    "        \"metadata\": [object],\n",
    "        \"target\": [str],\n",
    "        \"num_features\": [list],\n",
    "        \"cat_features\": [list],\n",
    "    }\n",
    "    \n",
    "    def __init__(self, metadata, target, num_features, cat_features):\n",
    "        self.metadata = metadata\n",
    "        self.target = target\n",
    "        self.num_features = num_features\n",
    "        self.cat_features = cat_features\n",
    "        self.synthesizer = SingleTablePreset(self.metadata, name=\"FAST_ML\")\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit_resample(self, X, y):\n",
    "        X = pd.DataFrame(X, columns=self.num_features + self.cat_features).reset_index(drop=True)\n",
    "        y = pd.DataFrame(y, columns=[self.target]).reset_index(drop=True)\n",
    "        df_train = pd.merge(X, y, left_index=True, right_index=True)\n",
    "        \n",
    "        X.to_csv(\"X.csv\", index = False)\n",
    "        y.to_csv(\"y.csv\", index = False)\n",
    "        df_train.to_csv(\"df_train.csv\", index = False)\n",
    "        \n",
    "        for col in self.cat_features:\n",
    "            df_train[col] = df_train[col].astype(int)\n",
    "        \n",
    "        self.synthesizer.fit(df_train)\n",
    "\n",
    "        class_counts = y[self.target].value_counts()\n",
    "        minority_class = class_counts.idxmin()\n",
    "        synthetic_samples_needed = class_counts.max() - class_counts.min()\n",
    "\n",
    "        if minority_class == 0:\n",
    "            balanced_conditions_0 = Condition(\n",
    "                num_rows=synthetic_samples_needed,\n",
    "                column_values={self.target: 0},\n",
    "            )\n",
    "            df_synth = self.synthesizer.sample_from_conditions(\n",
    "                conditions=[balanced_conditions_0]\n",
    "            )\n",
    "        elif minority_class == 1:\n",
    "            balanced_conditions_1 = Condition(\n",
    "                num_rows=synthetic_samples_needed,\n",
    "                column_values={self.target: 1},\n",
    "            )\n",
    "            df_synth = self.synthesizer.sample_from_conditions(\n",
    "                conditions=[balanced_conditions_1]\n",
    "            )\n",
    "        \n",
    "        # X_balanced = pd.concat([X, df_synth.drop(self.target, axis=1)], axis=0, ignore_index=True)\n",
    "        # y_balanced = pd.concat([y, df_synth[[self.target]]], axis=0, ignore_index=True)\n",
    "        \n",
    "        X_balanced = pd.concat([X.reset_index(drop=True), df_synth.drop(self.target, axis=1).reset_index(drop=True)], axis=0, ignore_index=True)\n",
    "        y_balanced = pd.concat([y.reset_index(drop=True), df_synth[[self.target]].reset_index(drop=True)], axis=0, ignore_index=True)\n",
    "        \n",
    "        X_balanced.to_csv(\"X_balanced.csv\", index = False)\n",
    "        y_balanced.to_csv(\"y_balanced.csv\", index = False)\n",
    "              \n",
    "        if sparse.issparse(X):\n",
    "            X_balanced = sparse.vstack([X_balanced], format=X.format)\n",
    "        else:\n",
    "            X_balanced = np.vstack([X_balanced])\n",
    "            \n",
    "        y_balanced = pd.Series(np.ravel(y_balanced))\n",
    "        \n",
    "        self.X_balanced = X_balanced\n",
    "        self.y_balanced = y_balanced\n",
    "        \n",
    "        X = X_balanced\n",
    "        y = y_balanced\n",
    "             \n",
    "        with open('debug.txt', 'w') as f:\n",
    "            f.write(f'X: {X.shape}\\n')\n",
    "            f.write(f'y: {y.shape}\\n')\n",
    "            f.write(f'y: \\n{y.value_counts()}\\n')\n",
    "            f.write(f'X_balanced: {X_balanced.shape}\\n')\n",
    "            f.write(f'y_balanced: {y_balanced.shape}\\n')\n",
    "            f.write(f'y_balanced: \\n{y_balanced.value_counts()}\\n')\n",
    "        \n",
    "        return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08071ca8-a93b-420b-b541-b5a19e1b6623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: TBTR\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n",
      "Transformed data before training:\n",
      "[[-0.23842126 -0.24237446  0.68180842 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.27230101  0.21117599  1.07425408 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.41270388 -0.21448779 -0.31162592 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.16862596 -0.18749428 -0.57620135 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.04337145 -0.25388811  0.38075105 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.8061746  -0.26400213 -0.18894016 ...  0.          1.\n",
      "   0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 658/658 [00:00<00:00, 4386.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data after training:\n",
      "[[-0.21166344 -0.33762947 -0.49941286 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.21278516 -0.34067606 -0.40718626 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.9442208  -0.29182961  0.40032815 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 2.78030359  1.71907593 -0.45520773 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.48150074 -0.2481489   0.08994409 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.25192411 -0.30419872  2.19945639 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 2...\n",
      "Transformed data before training:\n",
      "[[-0.30871038  0.24065804  1.23567589 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.09375205 -0.25392454 -0.57004662 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.30492228  0.23768361 -0.38786858 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.18233431 -0.19541242 -0.62724469 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.2376048  -0.24849916  2.24467356 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.89234954 -0.27909764 -0.19013089 ...  0.          1.\n",
      "   0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 646/646 [00:00<00:00, 4682.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data after training:\n",
      "[[-0.18619523 -0.25735474  0.49667146 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.32641519 -0.23377648 -0.26529448 ...  0.          1.\n",
      "   0.        ]\n",
      " [-0.22203803 -0.2550756  -0.31675633 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.13531351 -0.27104167 -0.42803875 ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.05357682 -0.23702423 10.96802688 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.04052252 -0.26708957  0.26575991 ...  0.          0.\n",
      "   1.        ]]\n",
      "Training fold 3...\n",
      "Transformed data before training:\n",
      "[[-0.23440643 -0.25518547  0.70753327 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.26680071  0.18822119  1.10053872 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.40104756 -0.2279225  -0.28731813 ...  0.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.15479367 -0.2015327  -0.55227095 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.03503099 -0.26644162  0.40604646 ...  0.          0.\n",
      "   1.        ]\n",
      " [-0.20575186 -0.24898092  1.99573582 ...  0.          0.\n",
      "   1.        ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tbtr_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTBTR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m tbtr_df\n",
      "Cell \u001b[1;32mIn[18], line 106\u001b[0m, in \u001b[0;36mevaluation_pipeline\u001b[1;34m(X, y, num_features, cat_features, sampling_strategy, metadata, target)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformed data before training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mX_train_transformed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39mnum_inner_loop_folds, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# scoring = accuracy ou roc_auc?\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalization\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfit_transform(X_test)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformed data after training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mX_test_transformed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:960\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    955\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabort_everything\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[0;32m    959\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n\u001b[1;32m--> 960\u001b[0m     \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabort_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:561\u001b[0m, in \u001b[0;36mLokyBackend.abort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mabort_everything\u001b[39m(\u001b[38;5;28mself\u001b[39m, ensure_ready\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_ready:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\executor.py:74\u001b[0m, in \u001b[0;36mMemmappingExecutor.terminate\u001b[1;34m(self, kill_workers)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mterminate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kill_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkill_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kill_workers:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;66;03m# When workers are killed in such a brutal manner, they cannot\u001b[39;00m\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;66;03m# execute the finalizer of their shared memmaps. The refcount of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m         \u001b[38;5;66;03m# unregister temporary resources from all contexts\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1185\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[1;34m(self, wait, kill_workers)\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread_wakeup\u001b[38;5;241m.\u001b[39mwakeup()\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[43mexecutor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor_manager_thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tbtr_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"TBTR\", metadata = metadata, target = target)\n",
    "tbtr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb70d4bb-3981-45f8-9b9c-5c8c38365abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: TBTR\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 666/666 [00:00<00:00, 11288.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 640/640 [00:00<00:00, 10847.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 656/656 [00:00<00:00, 11714.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 642/642 [00:00<00:00, 11068.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 644/644 [00:00<00:00, 11103.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 644/644 [00:00<00:00, 11103.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [00:00<00:00, 11241.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 658/658 [00:00<00:00, 11749.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 640/640 [00:00<00:00, 11227.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 654/654 [00:00<00:00, 11473.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 644/644 [00:00<00:00, 11291.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 656/656 [00:00<00:00, 11508.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [00:00<00:00, 11847.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 662/662 [00:00<00:00, 8486.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 634/634 [00:00<00:00, 10220.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [00:00<00:00, 11437.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 646/646 [00:00<00:00, 11333.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 660/660 [00:00<00:00, 11186.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 648/648 [00:00<00:00, 10124.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 642/642 [00:00<00:00, 11457.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 642/642 [00:00<00:00, 11264.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 650/650 [00:00<00:00, 11206.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 640/640 [00:00<00:00, 11227.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [00:00<00:00, 11051.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 664/664 [00:00<00:00, 11857.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 642/642 [00:00<00:00, 11263.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 644/644 [00:00<00:00, 10566.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 670/670 [00:00<00:00, 12408.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 648/648 [00:00<00:00, 11571.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 644/644 [00:00<00:00, 11298.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9100 +- 0.02</td>\n",
       "      <td>0.5200 +- 0.11</td>\n",
       "      <td>0.9172 +- 0.04</td>\n",
       "      <td>0.6569 +- 0.07</td>\n",
       "      <td>0.9134 +- 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9390 +- 0.02</td>\n",
       "      <td>0.6091 +- 0.08</td>\n",
       "      <td>0.9627 +- 0.06</td>\n",
       "      <td>0.7433 +- 0.07</td>\n",
       "      <td>0.9498 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9390 +- 0.01</td>\n",
       "      <td>0.6148 +- 0.10</td>\n",
       "      <td>0.8579 +- 0.09</td>\n",
       "      <td>0.7154 +- 0.10</td>\n",
       "      <td>0.9019 +- 0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9430 +- 0.01</td>\n",
       "      <td>0.6193 +- 0.12</td>\n",
       "      <td>0.9548 +- 0.05</td>\n",
       "      <td>0.7470 +- 0.09</td>\n",
       "      <td>0.9483 +- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9510 +- 0.02</td>\n",
       "      <td>0.6741 +- 0.13</td>\n",
       "      <td>0.8774 +- 0.13</td>\n",
       "      <td>0.7619 +- 0.13</td>\n",
       "      <td>0.9172 +- 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9440 +- 0.02</td>\n",
       "      <td>0.6473 +- 0.16</td>\n",
       "      <td>0.9088 +- 0.07</td>\n",
       "      <td>0.7439 +- 0.11</td>\n",
       "      <td>0.9287 +- 0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.9100 +- 0.02  0.5200 +- 0.11  0.9172 +- 0.04   \n",
       "1                  KNN  0.9390 +- 0.02  0.6091 +- 0.08  0.9627 +- 0.06   \n",
       "2  Logistic Regression  0.9390 +- 0.01  0.6148 +- 0.10  0.8579 +- 0.09   \n",
       "3                  MLP  0.9430 +- 0.01  0.6193 +- 0.12  0.9548 +- 0.05   \n",
       "4        Random Forest  0.9510 +- 0.02  0.6741 +- 0.13  0.8774 +- 0.13   \n",
       "5                  SVM  0.9440 +- 0.02  0.6473 +- 0.16  0.9088 +- 0.07   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.6569 +- 0.07  0.9134 +- 0.01  \n",
       "1  0.7433 +- 0.07  0.9498 +- 0.04  \n",
       "2  0.7154 +- 0.10  0.9019 +- 0.05  \n",
       "3  0.7470 +- 0.09  0.9483 +- 0.03  \n",
       "4  0.7619 +- 0.13  0.9172 +- 0.07  \n",
       "5  0.7439 +- 0.11  0.9287 +- 0.03  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbtr_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"TBTR\", metadata = metadata, target = target)\n",
    "tbtr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea05d20-be82-44d8-81d1-fd13cc430dd7",
   "metadata": {},
   "source": [
    "## TSTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08bb5c76-cd10-46b3-942c-d0138653a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSTR (Treinar com Dados Sint√©ticos, Testar com Dados Reais)\n",
    "# Dados Sint√©ticos Balanceados\n",
    "class SDVPipelineTSTR(BaseSampler):\n",
    "    _sampling_type = \"over-sampling\"\n",
    "    \n",
    "    _parameter_constraints = {\n",
    "        \"X\": [pd.DataFrame],\n",
    "        \"y\": [pd.DataFrame, pd.Series],\n",
    "        \"metadata\": [object],\n",
    "        \"target\": [str],\n",
    "        \"num_features\": [list],\n",
    "        \"cat_features\": [list],\n",
    "    }\n",
    "    \n",
    "    def __init__(self, metadata, target, num_features, cat_features):\n",
    "        self.metadata = metadata\n",
    "        self.target = target\n",
    "        self.num_features = num_features\n",
    "        self.cat_features = cat_features\n",
    "        self.synthesizer = SingleTablePreset(self.metadata, name=\"FAST_ML\")\n",
    "        super().__init__()\n",
    "        \n",
    "    def _fit_resample(self, X, y):\n",
    "        X = pd.DataFrame(X, columns=self.num_features + self.cat_features).reset_index(drop=True)\n",
    "        y = pd.DataFrame(y, columns=[self.target]).reset_index(drop=True)\n",
    "        df_train = pd.merge(X, y, left_index=True, right_index=True)\n",
    "        for col in self.cat_features:\n",
    "            df_train[col] = df_train[col].astype(int)\n",
    "        \n",
    "        self.synthesizer.fit(df_train)\n",
    "        \n",
    "        class_counts = y.value_counts()\n",
    "        majority_class = class_counts.idxmax()\n",
    "        synthetic_samples_needed = class_counts.max()\n",
    "\n",
    "        balanced_conditions_0 = Condition(\n",
    "            num_rows=synthetic_samples_needed,\n",
    "            column_values={target: 0},\n",
    "        )\n",
    "\n",
    "        balanced_conditions_1 = Condition(\n",
    "            num_rows=synthetic_samples_needed,\n",
    "            column_values={target: 1},\n",
    "        )\n",
    "\n",
    "        df_synth = self.synthesizer.sample_from_conditions(\n",
    "            conditions=[balanced_conditions_0, balanced_conditions_1]\n",
    "        )\n",
    "        \n",
    "        X_train_synth = df_synth.drop(target, axis=1)\n",
    "        y_train_synth = df_synth[target]\n",
    "        \n",
    "        if sparse.issparse(X):\n",
    "            X_train_synth = sparse.vstack([X_train_synth], format=X.format)\n",
    "        else:\n",
    "            X_train_synth = np.vstack([X_train_synth])\n",
    "            \n",
    "        y_train_synth = pd.Series(np.ravel(y_train_synth))\n",
    "\n",
    "        return X_train_synth, y_train_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b848a35f-966e-42c0-aaca-bedac48c16cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: TSTR\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1466/1466 [00:00<00:00, 9773.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:00<00:00, 9200.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1456/1456 [00:00<00:00, 9215.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1442/1442 [00:00<00:00, 7589.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1444/1444 [00:00<00:00, 7977.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1444/1444 [00:00<00:00, 10241.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1452/1452 [00:00<00:00, 9810.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1458/1458 [00:00<00:00, 10120.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1440/1440 [00:00<00:00, 8372.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1454/1454 [00:00<00:00, 5769.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1444/1444 [00:00<00:00, 10348.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1456/1456 [00:00<00:00, 10181.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1452/1452 [00:00<00:00, 10014.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1462/1462 [00:00<00:00, 7735.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1434/1434 [00:00<00:00, 10170.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1452/1452 [00:00<00:00, 9810.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1446/1446 [00:00<00:00, 8262.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1460/1460 [00:00<00:00, 8110.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1448/1448 [00:00<00:00, 6188.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1442/1442 [00:00<00:00, 6801.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1448/1448 [00:00<00:00, 6830.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1458/1458 [00:00<00:00, 6749.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1442/1442 [00:00<00:00, 3525.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1452/1452 [00:00<00:00, 6340.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1448/1448 [00:00<00:00, 6766.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1448/1448 [00:00<00:00, 6766.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1444/1444 [00:00<00:00, 6747.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1450/1450 [00:00<00:00, 6223.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1458/1458 [00:00<00:00, 6657.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling conditions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1448/1448 [00:00<00:00, 6552.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8990 +- 0.02</td>\n",
       "      <td>0.4655 +- 0.16</td>\n",
       "      <td>0.5953 +- 0.19</td>\n",
       "      <td>0.5121 +- 0.16</td>\n",
       "      <td>0.7624 +- 0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9140 +- 0.03</td>\n",
       "      <td>0.5393 +- 0.08</td>\n",
       "      <td>0.7173 +- 0.13</td>\n",
       "      <td>0.6096 +- 0.07</td>\n",
       "      <td>0.8271 +- 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9440 +- 0.02</td>\n",
       "      <td>0.6958 +- 0.10</td>\n",
       "      <td>0.7546 +- 0.12</td>\n",
       "      <td>0.7181 +- 0.08</td>\n",
       "      <td>0.8584 +- 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9490 +- 0.01</td>\n",
       "      <td>0.7265 +- 0.04</td>\n",
       "      <td>0.7287 +- 0.13</td>\n",
       "      <td>0.7212 +- 0.07</td>\n",
       "      <td>0.8500 +- 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9440 +- 0.03</td>\n",
       "      <td>0.7022 +- 0.18</td>\n",
       "      <td>0.7120 +- 0.18</td>\n",
       "      <td>0.7029 +- 0.17</td>\n",
       "      <td>0.8394 +- 0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9440 +- 0.01</td>\n",
       "      <td>0.6799 +- 0.09</td>\n",
       "      <td>0.7419 +- 0.11</td>\n",
       "      <td>0.7042 +- 0.07</td>\n",
       "      <td>0.8539 +- 0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.8990 +- 0.02  0.4655 +- 0.16  0.5953 +- 0.19   \n",
       "1                  KNN  0.9140 +- 0.03  0.5393 +- 0.08  0.7173 +- 0.13   \n",
       "2  Logistic Regression  0.9440 +- 0.02  0.6958 +- 0.10  0.7546 +- 0.12   \n",
       "3                  MLP  0.9490 +- 0.01  0.7265 +- 0.04  0.7287 +- 0.13   \n",
       "4        Random Forest  0.9440 +- 0.03  0.7022 +- 0.18  0.7120 +- 0.18   \n",
       "5                  SVM  0.9440 +- 0.01  0.6799 +- 0.09  0.7419 +- 0.11   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.5121 +- 0.16  0.7624 +- 0.09  \n",
       "1  0.6096 +- 0.07  0.8271 +- 0.07  \n",
       "2  0.7181 +- 0.08  0.8584 +- 0.06  \n",
       "3  0.7212 +- 0.07  0.8500 +- 0.06  \n",
       "4  0.7029 +- 0.17  0.8394 +- 0.10  \n",
       "5  0.7042 +- 0.07  0.8539 +- 0.06  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstr_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"TSTR\", metadata = metadata, target = target)\n",
    "tstr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fca3cf-2fb3-4f2f-af37-be33e97286d2",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538bb055-a694-414d-987c-847f36fdfb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline_smote(X, y, num_features: list , cat_features: list):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    num_outer_loop_folds = 5\n",
    "    num_inner_loop_folds = 5\n",
    "    results = []\n",
    "    \n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"Decision Tree\",\n",
    "            DecisionTreeClassifier(),\n",
    "            {\n",
    "                \"model__max_depth\": [None, 1, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"model__n_neighbors\": [1, 3, 5, 7, 10],\n",
    "                \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200, 300],\n",
    "                \"model__max_depth\": [None, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            {\n",
    "                \"model__C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"model__solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"MLP\",\n",
    "            MLPClassifier(max_iter=1000),\n",
    "            {\n",
    "                \"model__hidden_layer_sizes\": [(100,), (100, 50)],\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    standard_scaler = ColumnTransformer(\n",
    "        transformers=[(\"numerical_standard_scaler\", StandardScaler(), num_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "        \n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"\\nTraining Model: {model}\")\n",
    "        folds = KFold(n_splits=num_outer_loop_folds, shuffle=True).split(X, y)\n",
    "        for i, (train_index, test_index) in enumerate(folds):\n",
    "            print(f\"Training fold {i+1}...\")\n",
    "       \n",
    "            X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test, y_test = X.iloc[test_index, :], y.iloc[test_index]\n",
    "          \n",
    "            balance_classes_step = (\"balacing\", SMOTE(random_state=42))\n",
    "            normalization_step = (\"normalization\", standard_scaler)\n",
    "            model_step = (\"model\", model)\n",
    "            steps = [balance_classes_step, normalization_step, model_step]\n",
    "            pipeline = Pipeline(steps = steps)\n",
    "\n",
    "            clf = GridSearchCV(pipeline, param_grid, cv=num_inner_loop_folds, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classification\": name,\n",
    "                    \"Accuracy\": round(accuracy_test, 4),\n",
    "                    \"Precision\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "    mean_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).mean()\n",
    "    std_df = pd.DataFrame(results).groupby([\"Classification\"], as_index = False).std()\n",
    "    results_df = mean_std_results(mean_df, std_df)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc75c205-47c3-4488-b0cd-5da5214553c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Strategy: SMOTE\n",
      "\n",
      "Training Model: SVC()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: DecisionTreeClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: KNeighborsClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: RandomForestClassifier()\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: LogisticRegression(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n",
      "\n",
      "Training Model: MLPClassifier(max_iter=1000)\n",
      "Training fold 1...\n",
      "Training fold 2...\n",
      "Training fold 3...\n",
      "Training fold 4...\n",
      "Training fold 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9780 +- 0.01</td>\n",
       "      <td>0.8481 +- 0.10</td>\n",
       "      <td>0.9337 +- 0.05</td>\n",
       "      <td>0.8862 +- 0.06</td>\n",
       "      <td>0.9580 +- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9690 +- 0.02</td>\n",
       "      <td>0.7811 +- 0.11</td>\n",
       "      <td>0.9513 +- 0.03</td>\n",
       "      <td>0.8549 +- 0.07</td>\n",
       "      <td>0.9613 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9410 +- 0.02</td>\n",
       "      <td>0.6308 +- 0.05</td>\n",
       "      <td>0.9169 +- 0.08</td>\n",
       "      <td>0.7454 +- 0.05</td>\n",
       "      <td>0.9302 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.9790 +- 0.01</td>\n",
       "      <td>0.8520 +- 0.09</td>\n",
       "      <td>0.9415 +- 0.04</td>\n",
       "      <td>0.8911 +- 0.04</td>\n",
       "      <td>0.9625 +- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9820 +- 0.01</td>\n",
       "      <td>0.9058 +- 0.10</td>\n",
       "      <td>0.9318 +- 0.10</td>\n",
       "      <td>0.9117 +- 0.05</td>\n",
       "      <td>0.9592 +- 0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9660 +- 0.01</td>\n",
       "      <td>0.7533 +- 0.10</td>\n",
       "      <td>0.9148 +- 0.07</td>\n",
       "      <td>0.8229 +- 0.08</td>\n",
       "      <td>0.9426 +- 0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classification        Accuracy       Precision          Recall  \\\n",
       "0        Decision Tree  0.9780 +- 0.01  0.8481 +- 0.10  0.9337 +- 0.05   \n",
       "1                  KNN  0.9690 +- 0.02  0.7811 +- 0.11  0.9513 +- 0.03   \n",
       "2  Logistic Regression  0.9410 +- 0.02  0.6308 +- 0.05  0.9169 +- 0.08   \n",
       "3                  MLP  0.9790 +- 0.01  0.8520 +- 0.09  0.9415 +- 0.04   \n",
       "4        Random Forest  0.9820 +- 0.01  0.9058 +- 0.10  0.9318 +- 0.10   \n",
       "5                  SVM  0.9660 +- 0.01  0.7533 +- 0.10  0.9148 +- 0.07   \n",
       "\n",
       "         F1 Score         ROC/AUC  \n",
       "0  0.8862 +- 0.06  0.9580 +- 0.03  \n",
       "1  0.8549 +- 0.07  0.9613 +- 0.02  \n",
       "2  0.7454 +- 0.05  0.9302 +- 0.04  \n",
       "3  0.8911 +- 0.04  0.9625 +- 0.02  \n",
       "4  0.9117 +- 0.05  0.9592 +- 0.04  \n",
       "5  0.8229 +- 0.08  0.9426 +- 0.04  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_df = evaluation_pipeline(X = X, y = y, num_features = num_features, cat_features = cat_features, sampling_strategy = \"SMOTE\")\n",
    "smote_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de0ba8-4115-44a6-b161-13ea28b74427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5b762-27f2-41b4-a8d1-7f430ace404e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b7213-34eb-4949-92e8-a131cc670a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6338d-b075-4f52-8747-6e466904ce96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c653d-5e15-43cb-856c-b78a6ea5cb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789813d1-851c-4057-8489-fb16b786d541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d7c32-8581-4155-a88b-6ee0d4c16042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc580cc-fe13-41a5-a32c-ec68712d0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## debugs\n",
    "\n",
    "# with open('debug.txt', 'w') as f:\n",
    "#     f.write(f'synthetic_samples_needed: {synthetic_samples_needed}\\n')\n",
    "#     f.write(f'df_synth: {df_synth.shape}\\n')\n",
    "#     f.write(f'X: {X.shape}\\n')\n",
    "#     f.write(f'df_synth.drop(self.target, axis=1): {df_synth.drop(self.target, axis=1).shape}\\n')\n",
    "#     f.write(f'y: {y.shape}\\n')\n",
    "#     f.write(f'df_synth[self.target]: {df_synth[self.target].shape}\\n')\n",
    "#     f.write(f'y_balanced: {y_balanced.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048c307-8014-4d2c-b3a6-21675c5117bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = make_column_transformer(\n",
    "    (OneHotEncoder(), cat_features),\n",
    "    remainder='passthrough',\n",
    ")\n",
    "\n",
    "onehotencoder_step = (\"encoder\", onehotencoder)\n",
    "[onehotencoder_step, normalization_step, model_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2f1b9-59bd-48c2-9db6-8ae0c5db562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver a quest√£o do pq do X estar indo pra float, √© pra ficar int\n",
    "\n",
    "# Colocar um step do pipeline a mais para o Encoder, tem alguns datasets que eu preciso transformar dados categ√≥ricos em num√©ricos antes da avalia√ß√£o dos modelos\n",
    "# Consertar um erro aparente sobre os dados inteiros est√£o virando float, mas devem ser mantidos inteiros\n",
    "# Debugar o c√≥digo no sentido de analisar se as classes est√£o sendo realmente equilibradas\n",
    "# o SDV recebe os dados ainda splitados por conta do gridsearchcv que divide os dados em treino e val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
