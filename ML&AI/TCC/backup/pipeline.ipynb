{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07ad666-a63b-4f37-9f09-5c2d357eaa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "\n",
    "import sdgym\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import (\n",
    "    CTGANSynthesizer,\n",
    "    TVAESynthesizer,\n",
    "    GaussianCopulaSynthesizer,\n",
    "    CopulaGANSynthesizer,\n",
    ")\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.evaluation.single_table import (\n",
    "    evaluate_quality,\n",
    "    get_column_plot,\n",
    "    get_column_pair_plot,\n",
    "    run_diagnostic,\n",
    ")\n",
    "from sdv.sampling import Condition\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\", font_scale=0.5)\n",
    "custom_palette = [\"#8b4513\", \"#90ee90\", \"#545454\", \"#6a287e\", \"#f0be00\"]\n",
    "sns.set_palette(custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84048882-10de-44a4-8dfd-6ca74ee839e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(df, columns):\n",
    "    dummy_variables = []\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(df[column], prefix=column)\n",
    "        dummy_variables.append(dummies)\n",
    "    return dummy_variables\n",
    "\n",
    "def label_encode_columns(df, columns_to_encode):\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for column in columns_to_encode:\n",
    "        if column in df.columns:\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77fbde2a-fd48-4894-802f-62a7010969dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TBTR (Treinar com Dados Balanceados [SDV + Dados Reais], Testar com Dados Reais)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSDVPipelineBalanced\u001b[39;00m(\u001b[43mBaseEstimator\u001b[49m, TransformerMixin):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, metadata, name):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer \u001b[38;5;241m=\u001b[39m SingleTablePreset(metadata, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFAST_ML\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "# TBTR (Treinar com Dados Balanceados [SDV + Dados Reais], Testar com Dados Reais)\n",
    "class SDVPipelineBalanced(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, metadata, name):\n",
    "        self.synthesizer = SingleTablePreset(metadata, name=\"FAST_ML\")\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        df_train = pd.concat([X_train, y_train], axis=1)\n",
    "        self.synthesizer.fit(df_train)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_train, y_train, target, cat_features):\n",
    "        class_counts = y_train.value_counts()\n",
    "        minority_class = class_counts.idxmin()\n",
    "        synthetic_samples_needed = class_counts.max() - class_counts.min()\n",
    "\n",
    "        if minority_class == 0:\n",
    "            balanced_conditions_0 = Condition(\n",
    "                num_rows=synthetic_samples_needed,\n",
    "                column_values={target: 0},\n",
    "            )\n",
    "            df_synth = self.synthesizer.sample_from_conditions(\n",
    "                conditions=[balanced_conditions_0]\n",
    "            )\n",
    "        elif minority_class == 1:\n",
    "            balanced_conditions_1 = Condition(\n",
    "                num_rows=synthetic_samples_needed,\n",
    "                column_values={target: 1},\n",
    "            )\n",
    "            df_synth = self.synthesizer.sample_from_conditions(\n",
    "                conditions=[balanced_conditions_1]\n",
    "            )\n",
    "            \n",
    "        # onehotencoder\n",
    "        # dummy_variables = dummy(df_synth, cat_features)\n",
    "        # df_synth = pd.concat([df_synth] + dummy_variables, axis=1)\n",
    "        # df_synth = df_synth.drop(cat_features, axis=1)\n",
    "\n",
    "        X_train_balanced = pd.concat([X_train, df_synth.drop(target, axis=1)])\n",
    "        y_train_balanced = pd.concat([y_train, df_synth[target]])\n",
    "\n",
    "        return X_train_balanced, y_train_balanced\n",
    "\n",
    "\n",
    "# TSTR (Treinar com Dados Sintéticos, Testar com Dados Reais)\n",
    "# Dados Sintéticos Balanceados\n",
    "class SDVPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, metadata, name):\n",
    "        self.synthesizer = SingleTablePreset(metadata, name=\"FAST_ML\")\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        df_train = pd.concat([X_train, y_train], axis=1)\n",
    "        self.synthesizer.fit(df_train)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_train, y_train, target):\n",
    "        class_counts = y_train.value_counts()\n",
    "        majority_class = class_counts.idxmax()\n",
    "        synthetic_samples_needed = class_counts.max()\n",
    "\n",
    "        balanced_conditions_0 = Condition(\n",
    "            num_rows=synthetic_samples_needed,\n",
    "            column_values={target: 0},\n",
    "        )\n",
    "\n",
    "        balanced_conditions_1 = Condition(\n",
    "            num_rows=synthetic_samples_needed,\n",
    "            column_values={target: 1},\n",
    "        )\n",
    "\n",
    "        df_synth = self.synthesizer.sample_from_conditions(\n",
    "            conditions=[balanced_conditions_0, balanced_conditions_1]\n",
    "        )\n",
    "\n",
    "        # onehotencoder\n",
    "        # dummy_variables = dummy(df_synth, cat_features)\n",
    "        # df_synth = pd.concat([df_synth] + dummy_variables, axis=1)\n",
    "        # df_synth = df_synth.drop(cat_features, axis=1)\n",
    "\n",
    "        X_train_synth = df_synth.drop(target, axis=1)\n",
    "        y_train_synth = df_synth[target]\n",
    "\n",
    "        return X_train_synth, y_train_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2044461-eb19-4e4c-b086-d4bdd3a4e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_evaluation(X, y):\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    models = [\n",
    "        (\n",
    "            \"SVM\",\n",
    "            SVC(),\n",
    "            {\"model__C\": [0.1, 0.5, 1, 5, 10], \"model__kernel\": [\"linear\", \"rbf\"]},\n",
    "        ),\n",
    "        (\n",
    "            \"Decision Tree\",\n",
    "            DecisionTreeClassifier(),\n",
    "            {\n",
    "                \"model__max_depth\": [None, 1, 2, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5, 10],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"KNN\",\n",
    "            KNeighborsClassifier(),\n",
    "            {\n",
    "                \"model__n_neighbors\": [1, 3, 5, 7, 10],\n",
    "                \"model__weights\": [\"uniform\", \"distance\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Random Forest\",\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"model__n_estimators\": [100, 200, 300],\n",
    "                \"model__max_depth\": [None, 5, 10],\n",
    "                \"model__min_samples_split\": [2, 5],\n",
    "                \"model__min_samples_leaf\": [1, 5],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"Logistic Regression\",\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            {\n",
    "                \"model__C\": [0.1, 0.5, 1, 5, 10],\n",
    "                \"model__solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "            },\n",
    "        ),\n",
    "        (\n",
    "            \"MLP\",\n",
    "            MLPClassifier(max_iter=1000),\n",
    "            {\n",
    "                \"model__hidden_layer_sizes\": [(100,), (100, 50)],\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Normalização somente nos dados numericos\n",
    "    standard_scaler = ColumnTransformer(\n",
    "        transformers=[(\"numerical_standard_scaler\", StandardScaler(), num_features)],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    normalization_step = (\"normalization\", standard_scaler)\n",
    "\n",
    "    stratified_cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "    for name, model, param_grid in models:\n",
    "        for train_index, test_index in stratified_cv.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            model_step = (\"model\", model)\n",
    "            steps = [normalization_step, model_step]\n",
    "            pipeline = Pipeline(steps)\n",
    "            pipeline.fit(X_train, y_train)\n",
    "\n",
    "            clf = GridSearchCV(\n",
    "                pipeline, param_grid, cv=stratified_cv, refit=True, scoring=\"accuracy\"\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            best_model = clf.best_estimator_\n",
    "            best_params = clf.best_params_\n",
    "\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "            f1_test = f1_score(y_test, y_pred)\n",
    "            precision_test = precision_score(y_test, y_pred)\n",
    "            recall_test = recall_score(y_test, y_pred)\n",
    "            roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Classificador\": name,\n",
    "                    \"Acurácia\": round(accuracy_test, 4),\n",
    "                    \"Precisão\": round(precision_test, 4),\n",
    "                    \"Recall\": round(recall_test, 4),\n",
    "                    \"F1 Score\": round(f1_test, 4),\n",
    "                    \"ROC/AUC\": round(roc_auc_test, 4),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ee529-4ba4-44fb-880d-98abfbe17918",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1836ae6f-5218-43eb-8a6f-9011ef9e6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBS ###\n",
    "# mudar o path\n",
    "\n",
    "df = pd.read_csv(\"data/employee/employee.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9105ed77-f68a-4190-b42c-a39bb4c636ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2018</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2012</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2764 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0     Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1     Bachelors         2013       Pune            1   28  Female          No   \n",
       "2     Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3       Masters         2016  Bangalore            3   27    Male          No   \n",
       "4       Masters         2017       Pune            3   24    Male         Yes   \n",
       "...         ...          ...        ...          ...  ...     ...         ...   \n",
       "2759    Masters         2017       Pune            2   31  Female          No   \n",
       "2760  Bachelors         2016       Pune            3   30    Male          No   \n",
       "2761    Masters         2013       Pune            2   37    Male          No   \n",
       "2762    Masters         2018  New Delhi            3   27    Male          No   \n",
       "2763  Bachelors         2012  Bangalore            3   30    Male         Yes   \n",
       "\n",
       "      ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                             0           0  \n",
       "1                             3           1  \n",
       "2                             2           0  \n",
       "3                             5           1  \n",
       "4                             2           1  \n",
       "...                         ...         ...  \n",
       "2759                          2           0  \n",
       "2760                          2           0  \n",
       "2761                          2           1  \n",
       "2762                          5           1  \n",
       "2763                          2           0  \n",
       "\n",
       "[2764 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec992baa-888b-4987-bd7e-32b650d1b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"Education\", \"Gender\", \"City\", \"EverBenched\", \"PaymentTier\", \"ExperienceInCurrentDomain\"]\n",
    "num_features = [\"JoiningYear\"]\n",
    "target = \"LeaveOrNot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "486b7448-7fe6-4074-9aec-efb46b81260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "595fad12-0e23-43b6-9249-0a68fa79661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variables = dummy(df, cat_features)\n",
    "df = pd.concat([df] + dummy_variables, axis=1)\n",
    "df = df.drop(cat_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bf8f89a-8e94-4746-b2bf-0fb10e535d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target]\n",
    "X = df.drop(target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2a74c3-5ebf-43db-8a98-19cae6574697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificador</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>Precisão</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6492</td>\n",
       "      <td>0.6018</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>0.4121</td>\n",
       "      <td>0.5897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.6099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.4364</td>\n",
       "      <td>0.6054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.5824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.6408</td>\n",
       "      <td>0.3041</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.5968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.8114</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.7565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.7821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8134</td>\n",
       "      <td>0.8434</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.7311</td>\n",
       "      <td>0.7838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.5498</td>\n",
       "      <td>0.6755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.6763</td>\n",
       "      <td>0.6309</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.6941</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.6930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.7851</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.6791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.4101</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>0.6737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.7791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.5734</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.7404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.7882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>0.6898</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.7243</td>\n",
       "      <td>0.7804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4424</td>\n",
       "      <td>0.5319</td>\n",
       "      <td>0.6498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.3991</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.6175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.6454</td>\n",
       "      <td>0.4174</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.6341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6884</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.6483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.7794</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.5760</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.7434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>0.7537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.8101</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.7794</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.6009</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>0.7482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.7747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Classificador  Acurácia  Precisão  Recall  F1 Score  ROC/AUC\n",
       "0                   SVM    0.6492    0.6018  0.3134    0.4121   0.5897\n",
       "1                   SVM    0.6691    0.6606  0.3303    0.4404   0.6099\n",
       "2                   SVM    0.6637    0.6429  0.3303    0.4364   0.6054\n",
       "3                   SVM    0.6474    0.6186  0.2752    0.3810   0.5824\n",
       "4                   SVM    0.6594    0.6408  0.3041    0.4125   0.5968\n",
       "5         Decision Tree    0.8047    0.8114  0.6544    0.7245   0.7781\n",
       "6         Decision Tree    0.7884    0.8098  0.6055    0.6929   0.7565\n",
       "7         Decision Tree    0.8156    0.8718  0.6239    0.7273   0.7821\n",
       "8         Decision Tree    0.7902    0.8036  0.6193    0.6995   0.7604\n",
       "9         Decision Tree    0.8134    0.8434  0.6452    0.7311   0.7838\n",
       "10                  KNN    0.7306    0.7982  0.4194    0.5498   0.6755\n",
       "11                  KNN    0.6763    0.6309  0.4312    0.5123   0.6335\n",
       "12                  KNN    0.7251    0.6941  0.5413    0.6082   0.6930\n",
       "13                  KNN    0.7306    0.7851  0.4358    0.5605   0.6791\n",
       "14                  KNN    0.7301    0.8091  0.4101    0.5443   0.6737\n",
       "15        Random Forest    0.8119    0.8553  0.6267    0.7234   0.7791\n",
       "16        Random Forest    0.7758    0.8013  0.5734    0.6684   0.7404\n",
       "17        Random Forest    0.8210    0.8790  0.6330    0.7360   0.7882\n",
       "18        Random Forest    0.7902    0.8269  0.5917    0.6898   0.7556\n",
       "19        Random Forest    0.8152    0.8758  0.6175    0.7243   0.7804\n",
       "20  Logistic Regression    0.6944    0.6667  0.4424    0.5319   0.6498\n",
       "21  Logistic Regression    0.6637    0.6127  0.3991    0.4833   0.6175\n",
       "22  Logistic Regression    0.7052    0.6752  0.4862    0.5653   0.6670\n",
       "23  Logistic Regression    0.6799    0.6454  0.4174    0.5070   0.6341\n",
       "24  Logistic Regression    0.6884    0.6452  0.4608    0.5376   0.6483\n",
       "25                  MLP    0.7794    0.8065  0.5760    0.6720   0.7434\n",
       "26                  MLP    0.7812    0.7771  0.6239    0.6921   0.7537\n",
       "27                  MLP    0.8101    0.8343  0.6468    0.7287   0.7816\n",
       "28                  MLP    0.7794    0.7892  0.6009    0.6823   0.7482\n",
       "29                  MLP    0.8043    0.8263  0.6359    0.7188   0.7747"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df = pipeline_evaluation(X, y)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c2a2b-7aaf-4ca1-9c93-cd5b9ee3dcf4",
   "metadata": {},
   "source": [
    "## TSTR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dff23-d840-4bb4-bdd6-134baefc2509",
   "metadata": {},
   "source": [
    "## TBTR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a80938-80bf-4687-9a49-9e1d2f18225c",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
